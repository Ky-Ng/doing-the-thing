{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Doing The Thing: From Mechanical Turk to Mech Interp","text":"<p><sub> For motivation/momentum purposes: Started AI Safety journey 101 days ago with current daily streak of \"doing the thing\" for 1 consecutive days! </sub></p> Updates <ol> <li> <p>In the UK working from LISA from Monday, January 19th to Friday, January 23rd; worked from Trajan House, Oxford Monday, January 5th to Friday, January 16th</p> <p>a. Looking to meet more AI Safety folks! Please let me know if you would like to meet up; happy to travel to meet!</p> </li> <li> <p>Reflections from ARBOx including work in progress Theory of Change</p> </li> <li> <p>Currently working on an Automated Interpretability Project extending Neo et al. 2024 Interpreting Context Look Ups. I'm also interested in:</p> <p>a. Automated Circuit Tracing (e.g. developing Agents to automatically find circuits in Neuronpedia like attribution graphs)</p> <p>b. Cross-lingual alignment (e.g. Does aligning a model in English mean it's aligned in Chinese?)</p> </li> </ol> TLDR of Things I've Done Since Starting My AI Safety Journey 101 Days Ago <p>Projects</p> <ol> <li> <p>Cross-Linguistic Alignment: Does LoRA Fine Tuning a model on a task (e.g. respond in all CAPS) translate cross-linguistically? (Summary &amp;&amp; Github)</p> </li> <li> <p>Reproducing Neo et al. 2024 Interpreting Context Look Ups</p> </li> <li> <p>Multilingual Semantics Probe: Looking for Steering Vectors for semantically ambiguous sentences in English but not Mandarin </p> </li> <li> <p>Syntactic Dependencies in Transformers: Attention Patterns for Balanced Parentheses (Dyck) Language (Github)</p> </li> </ol> <p>Programs</p> <ol> <li> <p>ARBOx: 2 weeks of compressed ARENA curriculum; project on Cross-linguistic generalization of fine-tuning</p> </li> <li> <p>Attended NeurIPS Mech Interp 2025 Workshop and found some cool takeaways!</p> </li> <li> <p>Started being mentored by Sudhanshu Kasewa from 80,000 Hours</p> </li> </ol>"},{"location":"#what-is-this","title":"What is this?","text":"<p>Here it goes! I'm Kyle, a 4th year Computational Linguistics student at USC. This is the start of my AI Safety journey! I am very greatful to be mentored by Prof. Khalil Iskarous at USC.</p> <p>I learned about AI Safety from the Seattle Llama4 Hackathon on June 21st, 2025 where I learned of AI 2027. After finishing an awesome summer of engineering, I realized the problems which excite me the most lie at the crossroads of engineering and science (computation and linguistics). </p> <p>The urgent need for understanding increasingly capable AI models coupled with a burning passion for working at the interdisciplinary intersection of NLP, linguistics, and engineering at scale has sharpened my goal: to become an AI Safety researcher in Mechanistic Interpretability.</p>"},{"location":"#working-backwards","title":"Working Backwards","text":"<p>Sometimes (often) I get analysis paralysis or want to wait for the perfect {time, situation, background, preparation} to start which makes it difficult to get into pursuing my goals (and dreams). So this time around, I know my goal to become an AI Safety/Mech Interp researcher! After finding David Quarel's do the thing I decided that this site is a place where I will keep myself acountable for doing the thing.</p> <ul> <li>Doing --&gt; Working through math problems, reading papers, writing down lists of possible intersections of linguistics and NLP</li> <li>The Thing --&gt; Any of the above for at least 1 hour every day, with consistent (though not perfect) progress.</li> </ul> <p></p>"},{"location":"#what-is-dlog","title":"What is dlog?","text":"<p>I am starting this daily log or dlog where every day I will document my progress. I hope that the daily act of documenting will make me more resilient and help prove to myself how badly I want to be an interpetability researcher. With the help of AI, a macro pulls the daily logs into the summary you see below:</p> Extra Stuff (click me)"},{"location":"#wait-whats-computational-linguistics","title":"Wait What's Computational Linguistics?","text":"<p>As a Computational Linguistics student, I see Computational Linguistics as three parts:</p> <ol> <li>Linguistics = study of human language processing / cognition</li> <li>Mechanistic Interpretability = study of LLM language processing / cognition</li> <li>Computational Linguistics = Interdisciplinary approach to studying LLM language processing </li> </ol> <p>The Computational Linguistics topics that pull me at 9.8 m / s^2 are concepts like Information Theory and Probabilistic Phonology in addition to Theoretical Machine Learning and NLP.</p>"},{"location":"#what-does-ai-safety-and-mechanistic-interpretability-mean-to-me","title":"What does AI Safety and Mechanistic Interpretability mean to me?","text":"<ul> <li>I hope that having deep knowledge in both the fields of linguistics and ML/NLP can help me build a more holistic understanding of LLM cognition and language processing. </li> <li>I see Mechanistic Interpretability as a sort of psycholinguistics (the study of real-time processing of language) for LLMs. </li> <li>Furthermore, I see Mechanistic Interpretability as a foundational basis for understanding AI systems. Perhaps understanding models (such as like biological organisms) can support the other branches of AI Safety (alignment, control, governance, and more).</li> </ul>"},{"location":"#dlog-101-days-and-counting","title":"dlog: 101 Days and Counting","text":"<p>Total time focused so far: 304 hrs 28 mins throughout 101 days of learning</p> <p>Below are the latest updates (auto-generated). </p>"},{"location":"#latest-entries","title":"Latest entries","text":"<ul> <li> <p>2026-02-24 | 0 hr 0 min | Goal: Read up on Feature Splitting + Update ReadMe and Add Documentation for Eigen Spectrums Understand failure mode of Feature Absorption/Splitting in Attribution Graphs </p> <p><sub>Maxwell \u00b7 Circuits</sub></p> </li> <li> <p>2026-02-20 | 0 hr 0 min | Goal: Understand Path, Full, and Dyck Spectra and Eigenvectors   __  </p> <p><sub>Maxwell</sub></p> </li> <li> <p>2026-02-18 | 2 hr 0 min | Goal: Support Dyck Graphs + Understand Fully Connected/Star/Dyck Spectra Finish visualization of Graph Types </p> <p><sub>Maxwell</sub></p> </li> <li> <p>2026-02-17 | 2 hr 50 min | Goal: Extract + Visualize Eigenvalue Spectrums, Eigenvectors, and Topology for Star and Path Graphs Visualizations and Graph Type Extractions (Dyck Graphs WIP) </p> <p><sub>Maxwell</sub></p> </li> <li> <p>2026-02-16 | 0 hr 20 min | Goal: Extract Spectrums and Eigenvectors for Star and Path Graphs Documented tasks to do, punting completion to tomorrow </p> <p><sub>Maxwell</sub></p> </li> <li> <p>2026-02-13 | 1 hr 0 min | Goal: Weekly Research Meeting with Jonathan Derive the Rayleigh equation from first principles with Jonathan (edge vs. node centric) </p> <p><sub>Maxwell</sub></p> </li> <li> <p>2026-02-12 | 1 hr 25 min | Goal: Understand Rayleigh Quotient for Eigenvectors Previous days did not do documentation, will be more dilligent about documenting! Focusing on first principles intuitions for deriving eigenvalues as maximal disharmony of a graph </p> <p><sub>Maxwell</sub></p> </li> <li> <p>2026-02-07 | 10 hr 0 min | Goal: Building PCD on a Student Budget: docs Big day at the library! Understood PCD paper and started implementation; aimed to do with minimal AI Assistance </p> <p><sub>PCD \u00b7 Paper Reproduction</sub></p> </li> <li> <p>2026-02-06 | 2 hr 0 min | Goal: Understand Laplacian as Mean Value Operator | Read PCD Paper Deep Dive on how Path Graphs generate Second Derivatives | Read Section 3 of PCD paper </p> <p><sub>Eigenvectors \u00b7 Maxwell \u00b7 PCD</sub></p> </li> <li> <p>2026-02-05 | 2 hr 30 min | Goal: Eigenvectors and Spectrum Learning about Maxwell's Equations for Language Processing in LLMs </p> <p><sub>Eigenvectors \u00b7 Maxwell</sub></p> </li> </ul>"},{"location":"#todo-list","title":"Todo List","text":"<p>The todo list started getting too beefy and has been moved to its own todo page!</p>"},{"location":"dlog/2025-10-17/","title":"2025-10-17 | And So It Begins","text":"<p>Goal: Start getting into interpretability</p> <p>Summary: Accidentally started this website after finding ARENA and David Quarel's Do The Thing</p> <p>Work sessions</p> In Out 14:00 16:30 <p>Discovered ARENA RL tutorial (2.1) and started DFS (Depth First Search)ing through RL probability notation and basics</p> <p>Specifically, looking to understand this formula here</p> \\[ (s_{t+1} , r_t) \\sim P( \\cdot | s_t, a_t)\\]","tags":[]},{"location":"dlog/2025-10-18/","title":"2025-10-18 | ARENA","text":"<p>Goal: Applied to ARENA 7.0; Probability Prerequisites</p> <p>Summary: Introducing myself to Gaussian Distributions, Integration, and Entropy</p> <p>Work sessions</p> In Out 11:00 12:00 19:00 22:00 22:00 23:59","tags":["Applications","Information Theory","Probability","Calculus"]},{"location":"dlog/2025-10-18/#learning","title":"Learning","text":"<ol> <li>Work on understanding how Gaussian Distributions and Z-scores work</li> <li>Review of how to take an integral, applied to finding the probability density between two points</li> <li>Look into Shannon 1948 Information Theory PART I: DISCRETE NOISELESS SYSTEMS</li> </ol>","tags":["Applications","Information Theory","Probability","Calculus"]},{"location":"dlog/2025-10-18/#application","title":"Application","text":"<p>Applied to ARENA 7.0. The application was really fun since I learned about sandbagging and scheming. Since I am new to these concepts I wish I had more time to work on reading the papers/responding to the questions but most importantly, I did the thing!</p>","tags":["Applications","Information Theory","Probability","Calculus"]},{"location":"dlog/2025-10-19/","title":"2025-10-19 | Shannon","text":"<p>Goal: Shannon 1948 Discrete Noiseless Channel</p> <p>Summary: Multi-disciplinary approach to Interpretability, viewing models through the lens of Entropy</p> <p>Work sessions</p> In Out 19:00 23:00","tags":["Information Theory"]},{"location":"dlog/2025-10-19/#why-information-theory","title":"Why Information Theory","text":"<p>Shannon 1948 is a seminal text on the way scientists/engineers view how computer's transmit, store, and produce information.</p> <p>While written 77 years ago, concepts like Entropy (in fact, LLMs are trained on Cross-Entropy loss functions!), Mutual Information, and Noise perhaps may lead to greater insight which emerge from model training pressures.</p> <p>Nicely intersected with a reading for my Phonology Course</p>","tags":["Information Theory"]},{"location":"dlog/2025-10-20/","title":"2025-10-20 | Setup","text":"<p>Goal: Create this website</p> <p>Summary: Created website by following MkDocs-Material tutorial</p> <p>Work sessions</p> In Out 12:30 15:00 <p>Followed the Material for MkDocs: Full Tutorial To Build And Deploy Your Docs Portal tutorial and added workflow to automatically deploy to github pages on commits. Also debugged errors introduced by AI generated macro.</p> <p>Watched Neel Nanda \u2013 Mechanistic Interpretability: A Whirlwind Tour. I think I would like to try reproducing the paper Progress measures for grokking via mechanistic interpretability by Nanda et al.</p>","tags":["macros","documentation"]},{"location":"dlog/2025-10-21/","title":"2025-10-21 | Setup Cont.","text":"<p>Goal: Add homepage and latex support</p> <p>Summary: Added documentation for Monday/Tuesday</p> <p>Work sessions</p> In Out 09:00 09:27 11:20 11:40 21:40 22:25 <p>Added the index.md homepage and adding supporting with additional macros and latex.</p> <p>Now there's Latex support too! One of my favorite equations:</p> <p>\\(\\text{softmax}(\\frac{QK^\\top}{\\sqrt{d}})V\\)</p>","tags":["latex","documentation"]},{"location":"dlog/2025-10-22/","title":"2025-10-22 | Doc Updates","text":"<p>Goal: Update Past Days</p> <p>Summary: Added page 2025-10-17</p> <p>Work sessions</p> In Out 20:37 22:44 <ul> <li>Reference page: 2025-10-17</li> </ul>","tags":[]},{"location":"dlog/2025-10-23/","title":"2025-10-23 | MDPs","text":"<p>Goal: Finish adding past days and work on ARENA 2.1</p> <p>Summary: Introduction to MDPs, add docs for 2025-10-18 and 2025-10-19</p> <p>Work sessions</p> In Out 11:35 11:58 18:39 19:49","tags":["ARENA","RL","Bandits","MDPs","documentation"]},{"location":"dlog/2025-10-23/#arena-21-bandits-and-markov-decision-processes","title":"ARENA 2.1 Bandits and Markov Decision Processes","text":"<ul> <li>Quite a lot of math to go through. I think the lecture moves quite fast without too many examples so I will need to start watching the lecture again and likely use AI to make me some practice examples.</li> </ul> <p>Concept to review from Multi-Arm Bandits 1. Expected Values</p> <p>Concept to review from Markov Decision Processes</p> <ol> <li>What is $ \\hat{Q}_t(a) $</li> <li>Discounted Reward $ G_t $ and why geometric sequences are needed with the coefficient $ \\gamma $</li> <li>In the four tuple $ {S, T, A, R} $ what is a the simplex $ \\Delta A $</li> </ol> <p>The goal for tomorrow is to work through some simple problems from MDPs and Expected Values. The goal is to build up an intuition for Bellman's Equation.</p>","tags":["ARENA","RL","Bandits","MDPs","documentation"]},{"location":"dlog/2025-10-23/#updating-docs","title":"Updating docs","text":"<ul> <li>Added dcoumentation for 2025-10-18 and 2025-10-19</li> </ul>","tags":["ARENA","RL","Bandits","MDPs","documentation"]},{"location":"dlog/2025-10-23/#side-notes","title":"Side Notes","text":"<ul> <li>Might be a nice idea to include writing down the more formalized math down into Latex in a \"knowledge\" section for my own solidifcation and quick reference (like one page phonology tutorials) since my notes are kind of messy and free form</li> </ul>","tags":["ARENA","RL","Bandits","MDPs","documentation"]},{"location":"dlog/2025-10-24/","title":"2025-10-24 | Transformer Lens","text":"<p>Goal: Learn Transformer Lens</p> <p>Summary: Learning Transformer Lens for Encoder-Based Syntax Probe</p> <p>Work sessions</p> In Out 15:30 16:00 16:53 17:55","tags":["Syntax","Transformer Lens","Dyck Language"]},{"location":"dlog/2025-10-24/#dyck-language-probe","title":"Dyck Language Probe","text":"<p>Taking a quick break today on the ARENA curriculum to work on Dyck-Interp-Probe (though it was really fun to start sharing AI Safety ideas/ARENA curriculum with the Computational Linguistics Reading Group yesterday--next week we will start with a Karpathy Zero to Hero to ramp up for ARENA curriculum). </p> <p>The first version which I had worked on was programmed using Pytorch but since we're working on scaling up the experiments (binary searching number of layers needed for high performance and randomizing data partitions), it might be worthwhile to refactor for better collaboration. Super cool to see that Let's build GPT: from scratch, in code, spelled out. was where this project's programming began.</p> <p>This work is done in collaboration with Prof. Khalil Iskarous (Computational Linguistics at USC).</p>","tags":["Syntax","Transformer Lens","Dyck Language"]},{"location":"dlog/2025-10-24/#progress","title":"Progress","text":"<ol> <li> <p>Add support to load from a config rather than specifying in the code (decoupling for better quality of life for experimentation). Also added a logger and saved the training curves.</p> </li> <li> <p>Model performance seems to change throughout different runs, for example:</p> </li> </ol> <pre><code>Run A: Best Epoch = 147 with accuracy = 0.8352941274642944 and unconfidence = 0.12352941185235977\nRun B: Best Epoch = 149 with accuracy = 0.8588235378265381 and unconfidence = 0.10000000149011612\n</code></pre> <ul> <li>The most likely culprits are (1) Data shuffling (2) Model random initialization</li> <li> <p>I am leaning towards (2) being the issue since the data is not shuffled (but will need to verify this)</p> </li> <li> <p>In the experiments, the accuracy is hovering around 85%. Previously, I had seen accuracy close to ceiling (~96% on Validation Set).</p> </li> <li> <p>A follow up task is to tune AdamW optimizer hyperparameters to increase performance</p> </li> <li> <p>Initial experiment from 12 -&gt; 6 layers shows no performance degradation </p> </li> </ul> <pre><code>Run with 6 layers: Best Epoch = 152 with accuracy = 0.8705882430076599 and unconfidence = 0.10588235408067703\n</code></pre>","tags":["Syntax","Transformer Lens","Dyck Language"]},{"location":"dlog/2025-10-25/","title":"2025-10-25 | Applications","text":"<p>Goal: Work on ARENA 7.0 Application Follow Up</p> <p>Summary: Reflect on career goals, start reading Anthropic's Tracing the thoughts of a large language model</p> <p>Work sessions</p> In Out 15:44 16:15 22:36 23:15","tags":["Applications","Documentation"]},{"location":"dlog/2025-10-25/#documentation","title":"Documentation","text":"<ol> <li>Adding StatQuest videos to Todo list</li> <li>I think this will be a good way for me to help follow the concepts covered in ARENA 2.1 Bandits since a lot of the math went over my head!</li> <li>Making a new page for TODOs to not slow the homepage load</li> </ol>","tags":["Applications","Documentation"]},{"location":"dlog/2025-10-26/","title":"2025-10-26 | Applications","text":"<p>Goal: Apply to Research Opportunities</p> <p>Summary: Continue reading Anthropic's Tracing the thoughts of a large language model</p> <p>Work sessions</p> In Out 8:00 9:30 22:07 23:15","tags":["Applications"]},{"location":"dlog/2025-10-27/","title":"2025-10-27 | Stats","text":"<p>Goal: Continue Applications and Start StatQuest journey</p> <p>Summary: Watch StatQuest on Probability/Gaussian Distributions, Uniform Information Density Writeup</p> <p>Work sessions</p> In Out 0:00 1:00 14:15 15:05 15:45 16:10 16:42 17:18","tags":["Applications","Stats","Information Theory"]},{"location":"dlog/2025-10-27/#stats","title":"Stats","text":"<ul> <li>Completed 2 tutorials from StatQuest (Probability distributions and Gaussian Distributions)</li> <li> <p>Add page Stats and Probability Concepts</p> </li> <li> <p>Reference Page: Uniform Information Density Writeup</p> </li> </ul>","tags":["Applications","Stats","Information Theory"]},{"location":"dlog/2025-10-28/","title":"2025-10-28 | Apps","text":"<p>Goal: Continue Application Work!</p> <p>Summary: Looking for research/upskilling opportunities</p> <p>Work sessions</p> In Out 20:09 20:27 <p>Turns out sleep is very important, wasn't able to work for too long but will be back tomorrow.</p>","tags":["Applications"]},{"location":"dlog/2025-10-29/","title":"2025-10-29 | Apps","text":"<p>Goal: Continue Application Work Pt.2</p> <p>Summary: Looking for research/upskilling opportunities</p> <p>Work sessions</p> In Out 13:40 14:10 15:00 16:11 <p>Sleep I did and now I'm back!</p>","tags":["Applications"]},{"location":"dlog/2025-10-30/","title":"2025-10-30 | Apps","text":"<p>Goal: Lead first AI Safety Session!</p> <p>Summary: First time formally introducing AI Safety to Recursion Reading Group; briefly skim Anthropic's Signs of introspection in large language models</p> <p>Work sessions</p> In Out 20:30 21:45","tags":["Recursion Reading Group"]},{"location":"dlog/2025-10-30/#first-ai-safety-meeting","title":"First AI Safety Meeting","text":"<ol> <li> <p>It was nice to see people from different disciplines come together (CS, Cog Sci, Linguistics, Business) united by a shared interest in learning how to build NNs from scratch and captivated by AI Safety (we skimmed Detecting and reducing scheming in AI models)</p> </li> <li> <p>We followed the beginning of Karpathy's Zero to Hero Micrograd but it seemed that this wasn't the best way to engage folks. The reason why the Reading Group was so successful was that we were talking face-to-face and the main point of meeting was discussing complex ideas, not exactly watching a static pre-recorded video.</p> </li> <li> <p>Next week, we will try prepping a visualization-based, first-principle curriculum for staring work on NNs. Perhaps using this previous writeup could be a good start! Interpeting LLM Arithemtics Deep Dive</p> </li> </ol>","tags":["Recursion Reading Group"]},{"location":"dlog/2025-10-31/","title":"2025-10-31 | Stats","text":"<p>Goal: No Zero Days</p> <p>Summary: Mean, Variance, Std Deviation [StatQuest Video]</p> <p>Work sessions</p> In Out 16:53 17:00","tags":["Stats"]},{"location":"dlog/2025-10-31/#meaning-of-no-zero-days","title":"Meaning of No Zero Days","text":"<p>Even on the days where it seems impossible to make time for working on interpretability, I'm going to spend a little bit of time making progress! \u5805\u6301/\u575a\u6301\uff08ji\u00e1n ch\u01d0\uff09or perserverance towards a goal!</p> <p>Today was working on a bit of stats, tomorrow I will revisit this.</p>","tags":["Stats"]},{"location":"dlog/2025-11-01/","title":"2025-11-01 | Relative Links","text":"<p>Goal: Fix Relative Links Macro</p> <p>Summary: Understanding how to use Reg-Ex to turn relative links into absolute links</p> <p>Work sessions</p> In Out 10:00 12:00","tags":["Stats","Documentation","Conference"]},{"location":"dlog/2025-11-01/#conference-registration","title":"Conference Registration","text":"<ul> <li>Registered as a participant for NeurIPS Interpretability Workshop</li> </ul>","tags":["Stats","Documentation","Conference"]},{"location":"dlog/2025-11-02/","title":"2025-11-02 | Stats (a little)","text":"<p>Goal: No Zero Day</p> <p>Summary: Minimal No Zero Day, Reflecting on life</p> <p>Work sessions</p> In Out 21:51 22:02","tags":["Stats"]},{"location":"dlog/2025-11-02/#reflection","title":"Reflection","text":"<ul> <li>Happy Spring Forward! Today I did not spend as much time on Interpretability math but instead focused more on reflecting on where I have been and where I want to be. Working backwards from the goal of doing interpretability research in 2026!</li> </ul> <p>Aside: 3B1B has a pretty great video introducing Word Embeddings! Might be useful for the AI Safety group!</p>","tags":["Stats"]},{"location":"dlog/2025-11-02/#stats","title":"Stats","text":"<p>Continuing understanding Mean, Variance, Std Deviation [StatQuest Video]</p>","tags":["Stats"]},{"location":"dlog/2025-11-03/","title":"2025-11-03 | Stats","text":"<p>Goal: Mean, Variance, Std Deviation [StatQuest Video]</p> <p>Summary: Continue working through StatQuest, reflection on life goals and AI Saftey opportunities</p> <p>Work sessions</p> In Out 23:45 23:59","tags":["Stats"]},{"location":"dlog/2025-11-03/#reflection","title":"Reflection","text":"<p>It is definitley going to be a quite \"risky\" and more intense pathway to try to do AI Safety! I requested the prerequistie waiver for MATH 447 (mathematics of machine learning) and LING 602 (psycholinguistics stats) today!</p> <p>Adding this Stats todos: Why Dividing By N Underestimates the Variance</p>","tags":["Stats"]},{"location":"dlog/2025-11-04/","title":"2025-11-04 | Dyck Probe Debugging","text":"<p>Goal: Interpretability Probe Debugging</p> <p>Summary: Enfore reproducibility error by setting <code>torch.seed()</code></p> <p>Work sessions</p> In Out 00:23 1:00","tags":["Research","Dyck Probe"]},{"location":"dlog/2025-11-04/#reproducibility","title":"Reproducibility","text":"<p>In the original implementation of the paper from earlier this year, performance was at a ceiling (close to 98% accuracy). However, reproducing the model led to different training accuracies across runs. After verifying that the input data and order is consistent, the <code>torch.seed()</code> was the root cause of hte issue between different runs.</p>","tags":["Research","Dyck Probe"]},{"location":"dlog/2025-11-05/","title":"2025-11-05 | Career","text":"<p>Goal: Read 80,000 hours career guide</p> <p>Summary: Apply for 80,000 hour mentorship and watched Robert Miles AI Safety career video</p> <p>Work sessions</p> In Out 12:30 13:15 15:00 15:20","tags":["Reflection"]},{"location":"dlog/2025-11-05/#career-reflection","title":"Career Reflection","text":"<ul> <li>Found Map of AI Existential Safety from AISafety.com through ARENA Slack</li> <li>Watched AI Safety Career Advice! (And So Can You!) by Robert Miles AI Safety</li> <li>Read Dream Job Blogpost from 80,000 Hours</li> <li>Applied for 1-on-1 coaching session with 80,000 Hours</li> </ul>","tags":["Reflection"]},{"location":"dlog/2025-11-05/#direction-of-doing-the-thing","title":"Direction of Doing the Thing","text":"<ul> <li>Something I realized as Finals are approaching and I've been spending lots of time reading linguistics papers is that I have not been reading AI Safety papers as much!</li> <li>While I think it is good for me to continue to work on/brush up on the prerequisite knowledge in Running Todo List I want to start taking greater action in <code>doing the thing</code>.</li> <li>One way to take more action is perhaps to start trying to implement papers and DFS through concepts when finding them as blockers to achieving the next level of understanding. Since reproducing a paper is a finite goal and AI tools can help make structured plans, I think this can be a great way to start getting my hands dirty.</li> </ul>","tags":["Reflection"]},{"location":"dlog/2025-11-05/#fazl-barez-research-on-automatic-interpretability","title":"Fazl Barez Research on Automatic Interpretability","text":"<ul> <li>Found some pretty interesting work by Fazl Barez on using LLMs to automate analysis of circuits: </li> <li>Wish I was at this AI Safety and AI Alignment bootcamp</li> </ul>","tags":["Reflection"]},{"location":"dlog/2025-11-06/","title":"2025-11-06 | RRG","text":"<p>Goal: Recursion Reading Group ML Session 2</p> <p>Summary: Design/teach curriculum for motivating multiply add (dot product) intuition</p> <p>Work sessions</p> In Out 11:30 12:30 20:15 21:30","tags":["Teaching","RRG"]},{"location":"dlog/2025-11-06/#ai-safety","title":"AI Safety","text":"<ul> <li>Kicked off the meeting going over the abstract of Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</li> </ul>","tags":["Teaching","RRG"]},{"location":"dlog/2025-11-06/#neural-networks-from-scratch","title":"Neural Networks from Scratch","text":"<ul> <li>During the second meeting (See first meeting: 2025-10-30) of Neural Networks from Scratch (a new chapter of Recursion Reading Group (RRG) discussions), I met up with my co-lead to motivate ML from first principles before diving into the fancy math and libraries</li> <li>Specifically, we derived the intuition for multiplication as a similarity metric and addition as a way to aggregate similarity over pattern matching of an \\(x\\) and \\(w\\) vector.</li> <li>Since the cohort consists of Computational Linguistics, CS, and Cognitive Science majors, we used C++ to program a dot product calculator (on paper, note that USC's intro CS classes are in C++) and mapped the Dot Product to the first layer of a Neural Network</li> <li>Hopefully, by making this event unplugged and based on intuitions first, it provides the cohort mates a chance to talk and converse about AI Safety in addition to making sure no one is left behind</li> </ul>","tags":["Teaching","RRG"]},{"location":"dlog/2025-11-07/","title":"2025-11-07 | Reproducing Papers","text":"<p>Goal: Reproducing Interpretability Paper (Look Up Tables)</p> <p>Summary: Read abstract for Interpreting Context Look-ups in Transformers and look at Barez papers on interpretability</p> <p>Work sessions</p> In Out 00:00 1:00","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-07/#papers","title":"Papers","text":"<p>Looking over papers by Fazl Bazer to reproduce (reading abstract)</p> <ol> <li>Towards Interpreting Visual Information Processing in Vision-Language Model [2025]</li> <li>Interpreting Context Look-ups in Transformers [2024]</li> <li> <p>Chain-of-Thought Is Not Explainability [2025]</p> </li> <li> <p>Using GPT to generate a curriculum/plan on how to reproduce the Context Look-ups paper</p> </li> </ol>","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-08/","title":"2025-11-08 | Reproducing Papers","text":"<p>Goal: Reproducing Automated Interp Paper</p> <p>Summary: Read up to Background Section for (Neo et al. 2024)</p> <p>Work sessions</p> In Out 23:26 23:59","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-08/#neo-et-al-2024","title":"Neo et al. 2024","text":"<p>So far, I've read up to Section 3 Background. Below are my notes and concept prerequisites needed to reproduce the paper</p>","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-08/#high-level-algorithm-steps","title":"High Level Algorithm Steps","text":"<ol> <li>Identify next token neurons; find prompts that highly activate them</li> <li>Determine Attention heads most responsible for activating each next token neuron using head attribution score</li> <li>Use GPT-4 to generate explanations for activity patterns of these attention heads</li> <li> <p>Evaluate response quality by using GPT-4 zero shot classifier for head activity on a new prompt</p> </li> <li> <p>Very cool to see steps (3) and (4) which use GPT-4 to automate the interpretability work</p> </li> </ol>","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-08/#assumptions","title":"Assumptions","text":"<ol> <li>Associate Attention head output (new context-informed representation of a token) to next toke neuron<ol> <li>Next token neuron = neuron <code>output weight</code> corresponds with <code>embedding</code> of a token in vocab</li> </ol> </li> </ol>","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-08/#concepts-to-look-into","title":"Concepts to look into","text":"<ol> <li>Residual Stream as Shared Information</li> <li>Attention Head attribution to input weights of a Next Token Neuron not necessarily in the same decoder layer</li> <li>Next Token Neuron</li> </ol>","tags":["Reproducing Papers"]},{"location":"dlog/2025-11-09/","title":"2025-11-09 | Apps","text":"<p>Goal: Apply for FAR.AI San Diego Alignment Workshop</p> <p>Summary: Applied to FAR.AI Alignment Workshop conference to prepare for attending NeurIPS 2025 Conference</p> <p>Work sessions</p> In Out 23:00 23:57","tags":["Applications","Conferences"]},{"location":"dlog/2025-11-09/#neo-et-al-2024","title":"Neo et al. 2024","text":"<p>Today, trading progress on reproducing Neo et al. in favor of applying to conferences!</p>","tags":["Applications","Conferences"]},{"location":"dlog/2025-11-10/","title":"2025-11-10 | Courses","text":"<p>Goal: Look into Computational Biology Course</p> <p>Summary: Found Special topics Computational Biology course (interpretability for Neuroscience)</p> <p>Work sessions</p> In Out 23:00 23:30 <p>Looking into taking a Computational Biology course (BISC 499)</p> <p>From the syllabus: \"modeling of computations performed by small networks of neurons\" and \"neuronal signals to determine what information they encode\".</p>","tags":["Courses"]},{"location":"dlog/2025-11-11/","title":"2025-11-11 | Neo et al. 2024","text":"<p>Goal: Reproducing Neo et al. 2024</p> <p>Summary: Change of Basis and Next-token neurons</p> <p>Work sessions</p> In Out 09:30 10:00 13:00 15:15","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-11/#neo-et-al-2024","title":"Neo et al. 2024","text":"<ul> <li>Deep dive on 3Blue1Brown Change of basis | Chapter 13, Essence of linear algebra to understand how \\(W_{down}\\) stores information in its column vectors.</li> <li>Read through Neo et al. 2024 with working understanding of MLP Interpretability Next-token neuron analysis</li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-11/#next-steps","title":"Next Steps","text":"<ul> <li>Understand Individual Attention Head Attribution</li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-12/","title":"2025-11-12 | Neo et al. 2024 cont.","text":"<p>Goal: Reproducing Neo et al. 2024</p> <p>Summary: Solidify/document understanding in Interpreting Context Look Ups Notes</p> <p>Work sessions</p> In Out 20:15 20:50 21:50 23:55","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-12/#neo-et-al-2024","title":"Neo et al. 2024","text":"<ul> <li>Work through derivations of Next-token neurons</li> <li>In progress documentation of <code>Individual Head Attribution</code></li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-12/#todos-for-reproduction","title":"TODOs for Reproduction","text":"<ol> <li>Finish notes section on Head Attribution</li> <li>Load in GPT-2 Model and find position of Next-token Neurons    a. Verify that tokens at the very end layers are more correlated with token prediction   b. Can attempt to use GPT to explain the pattern</li> <li>Find Next-token neurons in final layers</li> <li>Attribute heads for each Next-token neurons in (3)</li> <li>Use GPT to provide explanation for contexts</li> <li>Ablations for confirmation</li> </ol> <p>Additional: 7. Note: I should also fix the writeup section on the (4) steps to success </p>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-13/","title":"2025-11-13 | Neo et al. 2024 cont.","text":"<p>Goal: Reproducing Neo et al. 2024 + Documenting + Apps</p> <p>Summary: Applying to Research; implementing Section 4.1 <code>Identifying Neurons</code> (github reproduction)</p> <p>Work sessions</p> In Out 01:00 01:35 08:00 09:00 14:00 14:55 15:15 15:45 18:20 19:50 22:30 23:59","tags":["Reproducing Papers","Neo et al. 2024","Apps"]},{"location":"dlog/2025-11-13/#neo-et-al-2024","title":"Neo et al. 2024","text":"<ol> <li>Continued updating Interpreting Context Look Ups Notes</li> <li>Implementing Section 4.1 <code>Identifying Neurons</code> but found that the distribution of next-token neurons are highly skewed to the final layer in GPT2-Small and GPT2-Large. Additionally, applying RMS norm on \\(W_{down}[:,i]\\) did not reproduce the same Figure 3 as in the paper</li> </ol> <p>Without Layer Norm: </p> <p>With Layer Norm: (matches the Figure 3 better distribution but orders of magnitude different) </p>","tags":["Reproducing Papers","Neo et al. 2024","Apps"]},{"location":"dlog/2025-11-14/","title":"2025-11-14 | Apps","text":"<p>Goal: Research Applications</p> <p>Summary: Worked on research applications!</p> <p>Work sessions</p> In Out 00:40 02:00 13:09 14:10","tags":["Apps"]},{"location":"dlog/2025-11-15/","title":"2025-11-15 | Reproducing Neo et al.","text":"<p>Goal: Reproducing Neo et al. 2024</p> <p>Summary: Completed Section 4.2 high level intuition: docs</p> <p>Work sessions</p> In Out 08:00 08:15 08:40 09:25 <ul> <li>Read Results and Conclusion section (previously read the only the methodology section)</li> <li>Start working on<code>Section 4.2 High-Activating Prompts</code>, completed high level intuition section</li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-16/","title":"2025-11-16 | Reproducing Neo et al.","text":"<p>Goal: Reproducing Neo et al. 2024</p> <p>Summary: Updating documentation on Section 4.2</p> <p>Work sessions</p> In Out 17:30 17:45","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-17/","title":"2025-11-17 | Career Advising","text":"<p>Goal: Respond to 80,000 Hours</p> <p>Summary: No Zero Days, responding to 80,000 hours for scheduling advising meeting</p> <p>Work sessions</p> In Out 23:00 23:05","tags":["80,000 hours","career"]},{"location":"dlog/2025-11-18/","title":"2025-11-18 | Reproducing Neo et al.","text":"<p>Goal: Reproducing Neo et al. 2024</p> <p>Summary: Writing my first model hook!</p> <p>Work sessions</p> In Out 23:30 23:50","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-18/#next-steps","title":"Next Steps","text":"<ul> <li>Finish tutorial (AI generated from first principles) on using hooks for saving model activations</li> <li>Apply hooks to reproduce Section 4.2 to find highly activating prompts</li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-19/","title":"2025-11-19 | Reproducing Neo et al.","text":"<p>Goal: Use Hook to Extract <code>nn.Linear</code> activations</p> <p>Summary: Understanding how to overwrite and extract activations (code)</p> <p>Work sessions</p> In Out 23:00 23:59","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-20/","title":"2025-11-20 | Apps","text":"<p>Goal: Applications</p> <p>Summary: Work on Application to ARBOx3</p> <p>Work sessions</p> In Out 15:15 15:50","tags":["Apps"]},{"location":"dlog/2025-11-21/","title":"2025-11-21 | Apps","text":"<p>Goal: Applications</p> <p>Summary: Work on Application to ARBOx3</p> <p>Work sessions</p> In Out 15:00 15:50","tags":["Apps"]},{"location":"dlog/2025-11-28/","title":"2025-11-28 | Reproducing Neo et al.","text":"<p>Goal: Reproduce Neo et al. 2024</p> <p>Summary: Add support for extracting prompt activations, in progress streaming in The Pile dataset</p> <p>Work sessions</p> In Out 15:00 16:30 20:15 21:30 <p>Back from a nice Thanksgiving Holiday! This is the first time of having a streak break but ready to continue working!</p>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-28/#reproducing-neo-et-al","title":"Reproducing Neo et al.","text":"<ul> <li>In progress code</li> <li>Created a phi function to calculate max neuron activation for a prompt/layer </li> <li>Using a top-k heap for sorting the highest (k=20) activating prompts for neuron</li> <li>Ramping up onto streaming <code>The Pile</code> dataset</li> <li>using the uncopyrighted version and using streaming for space efficiency</li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-29/","title":"2025-11-29 | Reproducing Neo et al.","text":"<p>Goal: Reproduce Neo et al. 2024</p> <p>Summary: Limitting memory footprint: <code>Stream</code> in The Pile and use Max Heap approach to store top-k activating prompts</p> <p>Work sessions</p> In Out 00:00 00:35 13:20 14:30","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-11-29/#reproducing-neo-et-al","title":"Reproducing Neo et al.","text":"<ul> <li>Battling through tokenizer batch shapes (see 2025-12-01 for the followup)</li> </ul>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-01/","title":"2025-12-01 | Reproducing Neo et al.","text":"<p>Goal: Reproduce Neo et al. 2024</p> <p>Summary: Allow tokenizer to process <code>Batch Size &gt; 1</code></p> <p>Work sessions</p> In Out 00:00 00:35 15:30 16:30","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-01/#reproducing-neo-et-al","title":"Reproducing Neo et al.","text":"<ol> <li>Allow tokenizer to have multiple batches</li> </ol> Tokenizer Padding ID <ul> <li><code>padding</code>: GPT-2 does not have a padding token by default</li> <li>instead, use the end-of-sequence (EOS) token instead <pre><code>tokenizer.pad_token = tokenizer.eos_token\ntokenizer.pad_token_id = tokenizer.eos_token_id\n</code></pre></li> </ul> <p>Thus, when tokenizing two prompts, the attention mask/padding will extend prompts to the longest prompt in the batch <pre><code>\"hi there\" --&gt; [5303, 612, 50256, 50256, 50256] # See that 50256 is the padding token\n\"what time is it?\" --&gt; [10919, 640, 318, 340, 30]\n</code></pre></p> <p>Therefore, we see the attention mask 0-ed out for <code>hi there</code> <pre><code>\"hi there\" --&gt; [1, 1, 0, 0, 0]\n\"what time is it?\" --&gt; [1, 1, 1, 1, 1]\n</code></pre></p> <ol> <li>Right-truncate long prompts with <code>truncation=True</code> in <code>tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)</code></li> <li>OOM (Out of Memory) issues with high batch size inference<ul> <li>Solution: support using Collab with VsCode to add GPU Support</li> <li>Ensure that tensors are on the same device during computation </li> <li>Results: 4 min = 4000 examples vs. before 2000</li> </ul> </li> </ol>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-01/#reading-list","title":"Reading List","text":"<p>Add How Can Interpretability Researchers Help AGI Go Well? to reading list</p>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-01/#next-steps","title":"Next Steps","text":"<ol> <li>finish section 4.2 activating neurons</li> <li>Write out the prompts to a serialized form (e.g. JSON/CSV) </li> <li>Truncate prompts to be 80% activation only</li> </ol>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-02/","title":"2025-12-02 | Reproducing Neo et al.","text":"<p>Goal: Reproduce Neo et al. 2024</p> <p>Summary: Fix Tokenizer to use left truncation and padding to keep max activating prompt right context; reach out to AI Safety folks</p> <p>Work sessions</p> In Out 14:45 15:50 22:45 23:50","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-02/#reading-list","title":"Reading List","text":"<p>Added Rohin Shah's Google DeepMind: An Approach to Technical AGI Safety and Security to reading list</p>","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-03/","title":"2025-12-03 | Matrix Rank Concept","text":"<p>Goal: Understand Matrix column vector of matrix as basis vectors and rank as their span</p> <p>Summary: Learn/visualize</p> <p>Work sessions</p> In Out 10:00 10:30","tags":["Linear Algebra"]},{"location":"dlog/2025-12-04/","title":"2025-12-04 | Mentorship","text":"<p>Goal: Leading ML from first Principles Meeting</p> <p>Summary: Lead backprop session at reading group, Meet with James Hindmarch to learn how to structure ML foundations curriculum</p> <p>Work sessions</p> In Out 20:30 21:30","tags":["Mentorship","Recursion Reading Group"]},{"location":"dlog/2025-12-05/","title":"2025-12-05 | No Zero Days","text":"<p>Goal: Prep NeurIPS Logistics</p> <p>Summary: No Zero Days!</p> <p>Work sessions</p> In Out 20:30 20:35","tags":["NeurIPS"]},{"location":"dlog/2025-12-06/","title":"2025-12-06 | Prep NeurIPS","text":"<p>Goal: Prepare questions and attitude for NeurIPS</p> <p>Summary: What do I want to get out of attending the Mech Interp 2025 Workshop?</p> <p>Work sessions</p> In Out 11:00 12:00","tags":["NeurIPS"]},{"location":"dlog/2025-12-06/#goals","title":"Goals","text":"<ol> <li> <p>Learn what people in AI Safety are interested in/how they think about AI Safety (horizon and impact)? Where do they want to be in a year and how do they want to get there?</p> </li> <li> <p>Meet new people and learn a different/change my perspective</p> </li> <li> <p>Learn a new technical concept; add at least 1 new concept to Todos</p> </li> </ol>","tags":["NeurIPS"]},{"location":"dlog/2025-12-06/#questions-to-ask-folks","title":"Questions to ask folks","text":"<ol> <li> <p>What are people looking to get out of today?</p> </li> <li> <p>Advice on how to make the most of an AI Safety program</p> </li> <li> <p>What pressing/itching problem are you thinking about now? What is something that would make you feel satisfied?</p> </li> </ol>","tags":["NeurIPS"]},{"location":"dlog/2025-12-06/#things-to-pack","title":"Things to pack","text":"<ol> <li> <p>Clif Bars</p> </li> <li> <p>QR Code</p> </li> <li> <p>Notepad</p> </li> <li> <p>Computer, no iPad</p> </li> <li> <p>Light Jacket (USC Jacket?)</p> </li> </ol>","tags":["NeurIPS"]},{"location":"dlog/2025-12-07/","title":"2025-12-07 | Takeaways from NeurIPS","text":"<p>Goal: Attend NeurIPS Mech Interp Conference</p> <p>Summary: In Defense of Curiosity vs. Pragamatic Approaches</p> <p>Work sessions</p> In Out 6:00 6:01","tags":["NeurIPS 2025","Conferences"]},{"location":"dlog/2025-12-07/#takeaways","title":"Takeaways","text":"<p>Moved notes from today into its own page</p>","tags":["NeurIPS 2025","Conferences"]},{"location":"dlog/2025-12-08/","title":"2025-12-08 | Timebox Prompt Probe","text":"<p>Goal: Timebox prompting modes for Inverse Scope</p> <p>Summary: Timebox (from Pragmatic approaches) to seeing how ChatGPT, Claude, DeepSeek, and Gemini answer a multiple choice question on inverse scope</p> <p>Work sessions</p> In Out 23:00 23:20","tags":["Inverse Scope Probe"]},{"location":"dlog/2025-12-09/","title":"2025-12-09 | AI Safety Talk/Catchup","text":"<p>Goal: AI Safety Talk with a Friend</p> <p>Summary: Catching up with a friend who works on AI Safety; focus on symbolic vs distributed computation</p> <p>Work sessions</p> In Out 15:00 16:00","tags":["Chats"]},{"location":"dlog/2025-12-10/","title":"2025-12-10 | Prep NeurIPS","text":"<p>Goal: Support serializing top_k prompt processsing</p> <p>Summary: Serialize top k prompts for each neuron</p> <p>Work sessions</p> In Out 23:40 23:59","tags":["Reproducing Papers","Neo et al. 2024"]},{"location":"dlog/2025-12-11/","title":"2025-12-11 | Semantic Trajectories","text":"<p>Goal: Understand math for Semantic Trajectories from Kulkarni et al. 2014</p> <p>Summary: Understand word2vec and historical time slice alignment using Procrustes analysis</p> <p>Work sessions</p> In Out 19:30 21:15","tags":["Reproducing Papers","Kulkarni et al. 2014"]},{"location":"dlog/2025-12-12/","title":"2025-12-12 | Semantic Trajectories","text":"<p>Goal: Use HistWords from Stanford NLP to reproduce semantic trajectories</p> <p>Summary: Battle python2 dependencies to reproduce semantic trajectories</p> <p>Work sessions</p> In Out 15:30 17:30","tags":["Reproducing Papers","Kulkarni et al. 2014"]},{"location":"dlog/2025-12-13/","title":"2025-12-13 | Documentation","text":"<p>Goal: Catch up on documentation</p> <p>Summary: Add documentation for 25.12.07 to 25.12.13</p> <p>Work sessions</p> In Out 23:10 23:45","tags":[]},{"location":"dlog/2025-12-18/","title":"2025-12-18 | Cross-linguistic Quantifier Scope Probe","text":"<p>Goal: Inverse Quantifier Scope: Start MATS Application Style Project</p> <p>Summary: Just finished finals! Now to try and be 'pragmatic' and work on a project</p> <p>Work sessions</p> In Out 12:00 13:05","tags":["Cross-linguistic Quantifier Scope"]},{"location":"dlog/2025-12-18/#goals","title":"Goals","text":"<ol> <li>Follow Neel Nanda's guide on how to work on an interpretability project</li> <li>Note: I think my focus on linguistics may be very different from what Neel's MATS stream is about; nevertheless I think it will be a good opportunity to start working on a novel research idea in a constrained time-box</li> </ol>","tags":["Cross-linguistic Quantifier Scope"]},{"location":"dlog/2025-12-18/#progress","title":"Progress","text":"<ol> <li>1 hour brainstorming session with GPT on roadmap for executing the experiment</li> <li>Started looking into the interpretability technique (linear probe) contenders and models (Gemma, Llama, Qwen, DeepSeek)</li> <li>A new TODO is to understand how Reasoning models work mathematically (high level intuition)</li> </ol>","tags":["Cross-linguistic Quantifier Scope"]},{"location":"dlog/2025-12-20/","title":"2025-12-20 | Break","text":"<p>Goal: Taking a break from work after an intense finals season!</p> <p>Summary: Will return on 2025-12-26</p> <p>Work sessions</p> In Out 12:00 12:00","tags":[]},{"location":"dlog/2025-12-26/","title":"2025-12-26 | Multilingual Semantics Probe","text":"<p>Goal: Start pipeline to evaluate model answers for ambiguous scope</p> <p>Summary: Generated Datasets/stimulus see docs</p> <p>Work sessions</p> In Out 16:00 17:20","tags":["Multilingual Semantics Probe"]},{"location":"dlog/2025-12-27/","title":"2025-12-27 | Multilingual Semantics Probe","text":"<p>Goal: Start Log Prob Probes</p> <p>Summary: Understand log prob delta (work on pencil/paper examples); concurrently write torch vectorized version see docs</p> <p>Work sessions</p> In Out 18:00 18:30 21:00 22:35 23:00 23:30","tags":["Multilingual Semantics Probe"]},{"location":"dlog/2025-12-28/","title":"2025-12-28 | Multilingual Semantics Probe","text":"<p>Goal: Collect Quantifier Scope Preferences per model (different model size); docs</p> <p>Summary: Finished Log Prob extraction; finding mixed results between Llama, GPT2, Qwen vs. Gemma</p> <p>Work sessions</p> In Out 08:00 09:00 17:00 18:00 22:00 23:30","tags":["Multilingual Semantics Probe"]},{"location":"dlog/2025-12-29/","title":"2025-12-29 | Multilingual Semantics Probe","text":"<p>Goal: Reach out to folks via email to meet in London; Probe larger models, start interp work; docs</p> <p>Summary: Tested many open source models and found that GPT2-ch correctly generalizes the expected behavior</p> <p>Work sessions</p> In Out 08:45 09:15 14:00 15:40 16:20 17:30 19:35 20:20 21:00 21:20 <p>Note: I did not send off my emails to folks I would like to meet in London. I will need to fast follow this tomorrow.</p>","tags":["Multilingual Semantics Probe","Messaging"]},{"location":"dlog/2025-12-30/","title":"2025-12-30 | Multilingual Semantics Probe","text":"<p>Goal: Find the interpretability technique to use to extract inverse/surface scope; docs</p> <p>Summary: Used GPT-2-Chinese and found that model is undertrained. Switching to using Qwen2.5 which has high English/Mandarin proficiency. EU quantification shows surface preference for both languages, Mandarin only Surface.</p> <p>Work sessions</p> In Out 12:45 13:25 15:15 13:25 16:00 16:15 16:45 17:35 21:20 23:50","tags":["Multilingual Semantics Probe","Messaging"]},{"location":"dlog/2025-12-31/","title":"2025-12-31 | Multilingual Semantics Probe","text":"<p>Goal: Look for steering vectors in Multilingual Semantics Probe and writeup results; docs</p> <p>Summary: Finish code to extract steering vectors per quantifier scope per language</p> <p>Work sessions</p> In Out 11:20 13:25 16:20 17:10","tags":["Multilingual Semantics Probe","Messaging"]},{"location":"dlog/2026-01-01/","title":"2026-01-01 | Multilingual Semantics Probe","text":"<p>Goal: Travelling to London</p> <p>Summary: Time difference means that today disappeared</p> <p>Work sessions</p> In Out 00:00 00:00","tags":["Time Travel"]},{"location":"dlog/2026-01-02/","title":"2026-01-02 | Multilingual Semantics Probe","text":"<p>Goal: Finalize steering vectors and do writeup; docs</p> <p>Summary: Finish executive summary and experiments for steering vectors</p> <p>Work sessions</p> In Out 15:10 16:10 17:00 18:00 19:30 21:00 22:30 23:55","tags":["Multilingual Semantics Probe"]},{"location":"dlog/2026-01-03/","title":"2026-01-03 | Multilingual Semantics Probe","text":"<p>Goal: Refleced on and improvedexecutive summary]; figured out how to get to Oxford</p> <p>Summary: Reflection on follow up experiments for executive summary</p> <p>Work sessions</p> In Out 00:00 03:00","tags":["Reflection","Writeup"]},{"location":"dlog/2026-01-04/","title":"2026-01-04 | Travel to ARBOx","text":"<p>Goal: Travel from London to Oxford; dinner with ARBOx participants and discuss research interests</p> <p>Summary: Dinner with my housemates for ARBOx was very insightful! Learned about Continuous Chain of Thought (Coconut) and genetics</p> <p>Work sessions</p> In Out 18:00 19:00","tags":["Travel"]},{"location":"dlog/2026-01-05/","title":"2026-01-05 | ARBOx Day 1","text":"<p>Goal: Day 1 of ARBOx</p> <p>Summary: Introduction to ARBOx, worked on ARENA notebook 0.2 CNNs and ResNets; also fell sick</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","ARENA Notebook","CNNs","ResNets"]},{"location":"dlog/2026-01-06/","title":"2026-01-06 | ARBOx Day 2","text":"<p>Goal: Day 2 of ARBOx: Transformers from Scratch</p> <p>Summary: ARENA 1.1: Transformers from Scratch (GPT2)</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","ARENA Notebook","Transformers from Scratch"]},{"location":"dlog/2026-01-07/","title":"2026-01-07 | ARBOx Day 3","text":"<p>Goal: Day 3 of ARBOx: Intro to MechInterp/Transformer Lens</p> <p>Summary: ARENA 1.2 Notebook: Induction Heads, K-Composition; also had interesting talks about AI Safety world view with Eric Drexler; Pytorch at the Pub</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","ARENA Notebook","MechInterp"]},{"location":"dlog/2026-01-07/#pytorch-at-the-pub","title":"Pytorch at the Pub","text":"<p>Helped explain Pytorch fundamentals and Einops to ARBOx friends at the pub next to Trajan House! First time for everything!</p>","tags":["ARBOx","ARENA Notebook","MechInterp"]},{"location":"dlog/2026-01-08/","title":"2026-01-08 | ARBOx Day 4","text":"<p>Goal: Day 4 of ARBOx: Superposition and SAEs</p> <p>Summary: ARENA 1.3 Notebook: Introduction to Superposition and using SAEs</p> <p>Work sessions</p> In Out 10:00 18:00 <p>While I have an intuition of the Toy Models of Superposition and how feature directions often have entangled concepts, reading the original Toy Models of Superposition will help me improve my theoretical understanding of MechInterp. </p> <p>Added to todos</p> <p>Also added Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</p>","tags":["ARBOx","ARENA Notebook","MechInterp","Toy Models of Superposition","SAEs"]},{"location":"dlog/2026-01-09/","title":"2026-01-09 | ARBOx Day 5","text":"<p>Goal: Day 5 of ARBOx: Indirect Object Identification Paper Reproduction</p> <p>Summary: ARENA 1.4.1 Notebook: Circuits in IOI</p> <p>Work sessions</p> In Out 10:00 18:00 <p>Learning about circuits was one of the coolest things in the MechInterp section of ARBOx. This is the most clear evidence to me that models are implementing very non-trivial algorithms and are not just \"stochastic parrots\".</p> <p>Left 1 hour early in the day to go to the LISA ARENA x ARBOx social.</p> <p>Key concepts that I will need to revisit:</p> <ol> <li> <p>Logit, Head, Layer Attribution, Logit Diffs</p> </li> <li> <p>Activation Patching</p> </li> <li> <p>Path Patching</p> </li> </ol>","tags":["ARBOx","ARENA Notebook","MechInterp","Paper Reproduction","IOI"]},{"location":"dlog/2026-01-10/","title":"2026-01-10 | Apps","text":"<p>Goal: Work on SPAR Application</p> <p>Summary: Look into SPAR Streams to apply to</p> <p>Work sessions</p> In Out 15:00 18:00","tags":["ARBOx","Applications"]},{"location":"dlog/2026-01-11/","title":"2026-01-11 | Apps","text":"<p>Goal: Work on SPAR Application/MATS Applications</p> <p>Summary: Start brainstorming answers to MATS application</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","Applications"]},{"location":"dlog/2026-01-12/","title":"2026-01-12 | ARBOx Day 6","text":"<p>Goal: Day 6 of ARBOx: Intro to RL</p> <p>Summary: ARENA 2.1 Notebook: Q-Learning, SARSA, Epsilon-Greedy Policies</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","ARENA Notebook","Reinforcement Learning"]},{"location":"dlog/2026-01-13/","title":"2026-01-13 | ARBOx Day 6","text":"<p>Goal: Day 7 of ARBOx: Proximal Policy Learning (PPO)</p> <p>Summary: ARENA 2.2 Notebook: Deep Q-Learning, Agent/Critic Networks; this stuff was hard</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","ARENA Notebook","Reinforcement Learning"]},{"location":"dlog/2026-01-14/","title":"2026-01-14 | ARBOx Day 8","text":"<p>Goal: Day 8 of ARBOx: Cross-lingual Alignment Generalization</p> <p>Summary: Project Selection and Scaffolding for testing whether models generalize CAPS fine tuning in English to German</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","Cross-lingual alignment"]},{"location":"dlog/2026-01-15/","title":"2026-01-15 | ARBOx Day 9","text":"<p>Goal: Day 9 of ARBOx: Cross-lingual Alignment Generalization + Refusal Task</p> <p>Summary: Fine tuning Qwen2.5 in German, English, Russian and comparing cross-linguistic transfer; Also test generalization of Refusal</p> <p>Work sessions</p> In Out 10:00 18:00","tags":["ARBOx","Cross-lingual alignment"]},{"location":"dlog/2026-01-16/","title":"2026-01-16 | ARBOx Day 10 (Last Day :/ )","text":"<p>Goal: Day 10 of ARBOx: Cross-lingual Alignment Generalization + Refusal Task</p> <p>Summary: Extract steering vectors for language (e.g. German - English), apply to models to test how entangled a concept is with the language</p> <p>Work sessions</p> In Out 10:00 18:00 <p>Lesson learned: Do rigorous literature review! We found that the paper Refusal Direction is Universal Across Safety-Aligned Languages; however, things even seem more complicated! See LLMs Encode Harmfulness and Refusal Separately.</p> <p>We also presented the results during the ARBOx final presentations! Will work on the writeup sometime next week!</p>","tags":["ARBOx","Cross-lingual alignment"]},{"location":"dlog/2026-01-17/","title":"2026-01-17 | ARBOx Reflections","text":"<p>Goal: Reflect on 2 weeks of AI Safety in Oxford (ARBOx) | Plan upcoming week</p> <p>Summary: Work on planning questions for MATS application and writing reflection for ARBOx</p> <p>Work sessions</p> In Out 14:00 16:10 18:00 22:00","tags":["Reflections","Documentation"]},{"location":"dlog/2026-01-18/","title":"2026-01-17 | Apps","text":"<p>Goal: MATS Application</p> <p>Summary: Reading Automated Interpretability Agenda, Latent QA, Predictive Concept Decoder (PCD), and Activation Oracles</p> <p>Work sessions</p> In Out 16:00 17:30 20:00 23:59","tags":["Apps"]},{"location":"dlog/2026-01-19/","title":"2026-01-19 | Apps","text":"<p>Goal: MATS Application | First day in LISA</p> <p>Summary: Finished Stream Specific Questions! Attended David Quarel's lecture on RL</p> <p>Work sessions</p> In Out 00:00 02:30 09:50 11:50 13:00 11:50","tags":["Apps"]},{"location":"dlog/2026-01-20/","title":"2026-01-20 | LISA Coworking - Circuits","text":"<p>Goal: LISA Coworking - Circuits Prerequisites | Plan and start project | DQN Lecture</p> <p>Summary: Started reading Mathematical Framework for Transformers but realized to start backwards from ACDC instead; started watching video overview from Nanda + Conmy</p> <p>Work sessions</p> In Out 09:30 22:00","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-20/#plan-for-today","title":"Plan for Today","text":"<ol> <li> <p>Read <code>A Mathematical Framework for Transformer Circuits</code></p> </li> <li> <p>Read <code>Automated Circuit Interpretation via Probe Prompting</code> https://www.lesswrong.com/posts/zQqGhKPqaCBZZDCge/automated-circuit-interpretation-via-probe-prompting</p> </li> </ol> <p>2.5. IOI either implement (Neel Nanda has a video)/ARENA and read the paper</p> <ol> <li> <p>Read more Anthropic Circuit related papers</p> </li> <li> <p>Read Circuit Tracing Automation related papers</p> </li> <li> <p>Develop a tractable plan for a minimal project and writeup by the EOW (Friday, January 23rd)</p> </li> <li> <p>Thinking now I have about 18 hours over the next 3 days so perhaps I can do a Neel Nanda style MATS application project on this!</p> </li> </ol>","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-20/#meetings","title":"Meetings","text":"<ol> <li> <p>Prep for meeting with Evan Feder</p> </li> <li> <p>Prep for meeting with J Rosser</p> </li> <li> <p>Prep to learn about Singular Learning Theory from Ilya Shirokov</p> </li> </ol>","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-20/#checklist-concepts-to-know-by-eod","title":"Checklist Concepts to know by EOD","text":"<ul> <li> Negative writes (either through MLP or MHA)?</li> </ul>","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-20/#interesting-linear-subspace-write-strength-for-layer-0-head-0-for-qwen-25","title":"Interesting Linear Subspace Write Strength for Layer 0 Head 0 for Qwen 2.5","text":"","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-21/","title":"2026-01-21 | LISA Coworking - ACDC and Meetings","text":"<p>Goal: LISA Coworking - Circuits Deep Dive | Start Programming KL Divergence | David Quarel PPO Lecture</p> <p>Summary: Implemented KL Divergence/dive into math, meetings!</p> <p>Work sessions</p> In Out 9:00 19:00","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-21/#meetings","title":"Meetings","text":"<ol> <li> <p>Met with J Rosser (one of the nicest people I've met)</p> </li> <li> <p>Clement Dumas currently doing MATS (super patient at explaining and very insightful)</p> </li> </ol>","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-21/#progress","title":"Progress","text":"<ul> <li> <p>A little bit slower progress on ACDC then I would have liked. I started unit testing KL Divergence and understanding the ACDC algorithm better (something I got tripped up on was that the activation patching is the \"removal of the edge\" not actually ablating (<code>zeroing</code>)) it</p> </li> <li> <p>Finished watching up to the paper review from Neel Nanda and Arthur Conmy (part 1 and part 2)</p> </li> <li> <p>Coordinated timing of meetings and work for Thursday/tenatively Friday (tomorrow is RLHF!)</p> </li> </ul>","tags":["Paper Reading","ACDC"]},{"location":"dlog/2026-01-22/","title":"2026-01-22 | LISA Coworking - ACDC","text":"<p>Goal: LISA/LEAH Coworking - Circuits Deep Dive | David Quarel RLHF + LoRA Lecture</p> <p>Summary: Understanding the Path Patching/ACDC Algorithm</p> <p>Work sessions</p> In Out 9:00 23:00 <ol> <li> <p>Deep dive into IOI paper</p> </li> <li> <p>Deep dive into ACDC paper</p> </li> <li> <p>Prepare questions on Induction Heads and Path Patching for ARENA TAs (thankful that David, Dennis, Nicky, and James were very open to explaining questions)</p> </li> </ol>","tags":["Paper Reading","ACDC","IOI"]},{"location":"dlog/2026-01-23/","title":"2026-01-23 | LISA Coworking - ACDC","text":"<p>Goal: LISA Coworking | Path Patching and ACDC | Prepare for SPAR Interview</p> <p>Summary: Understanding the Path Patching/ACDC Algorithm</p> <p>Work sessions</p> In Out 07:30 19:00 <ol> <li> <p>Understand that there's either (1) implicitly an assumption of orthogonality when heads write to subspaces to avoid overwriting each other or (2) a type of superposition that allows heads to write to a specific space but disentangle it</p> </li> <li> <p>Went through path patching and induction heads wth David</p> </li> </ol>","tags":["Paper Reading","ACDC","IOI"]},{"location":"dlog/2026-01-24/","title":"2026-01-24 | Reading &amp;&amp; Thesis","text":"<p>Goal: Read Seminal Papers in Interpretability | Propose Master's Thesis</p> <p>Summary: Deep dive into Tensor Products used in Mathematical Framework for Transformers | Start Literature Review for Thesis</p> <p>Work sessions</p> In Out 10:40 16:30 <p>Today is going to be a little bit weird! Travelling = No Wifi = No AI Assistance to understand papers. This will be super interesting :)</p>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#work-session-goals","title":"Work Session Goals","text":"","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#potential-goals-for-work-session","title":"Potential Goals for work session","text":"<ul> <li> <p>Don't fall asleep so I don't get jet lag</p> </li> <li> <p>Read </p> </li> <li>A Mathematical Framework for Transformers (this is probably the most important one and the one that will take the longest)</li> <li>Towards Monosemanticity</li> <li>Scaling Monosemanticity</li> <li>Transcoders Paper</li> <li>Building and evaluating alignment auditing agents</li> <li> <p>Unfortunately can't do Toy Models of Superposition because I didn't save that paper</p> </li> <li> <p>ACDC; probably better to program at a real desk and have internet connection (AI and pytorch docs)</p> </li> <li> <p>Thank you emails (realized this is kind of hard without wifi)</p> </li> <li> <p>Notes to family and friends (this is possible cuz it's just ink!)</p> </li> </ul>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#priorities-and-timing","title":"Priorities and Timing","text":"<ol> <li> <p>Notes</p> </li> <li> <p>Write Thesis Proposal and Experiments</p> </li> <li> <p>Read Interp literature</p> </li> </ol> <p>There's 7.5 hours left in the flight (wow time goes by fast)! I assume there will be a feeding time so -1 hour + 30 mins of breakat least somewhere in between 6 hours now</p>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#quick-jot-of-common-experimental-methods-in-interpretability","title":"Quick Jot of Common Experimental Methods in Interpretability","text":"","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#circuits","title":"Circuits","text":"<ol> <li>Attention (QK-OV) Circuits; Path Patching </li> <li>Attribution Graphs; use either Cross Layer Transcoders (CLTs) or per-layer Transcoders</li> </ol>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#sparsifying-methods","title":"Sparsifying Methods","text":"","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#linear-methods","title":"Linear Methods","text":"<ol> <li>Steering Vectors: Assume that an activation (let's say in the residual stream) \\(h\\) can be composed of steering vector \\(v\\), on-or-off features \\(v\\) is a vector of all 1's or -1's, and  noise \\(\\epsilon\\) such that</li> </ol> <p>$$h = z \\cdot w + \\epsilon$</p> <ul> <li> <p>TODO: is v all 1's or all -1'2 with shape d_model if for residual? Does w need to be sparse? I don't think so</p> </li> <li> <p>Linear Probe: \\(y hat = \\sigma (v \\cdot x + b)\\)</p> </li> <li> <p>TODO: does </p> </li> <li> <p>LoRA Adaptors (not too much work on interpreting LoRA adaptors to my knowledge since it comes from a training efficiency motivation): For each weight matrix in the model, learn a lower rank (usually 2-16) A and B matrix to add:</p> </li> </ul> <p>Given a weight matrix \\(W \\in \\mathbb{R}^{d1 \\times d2}\\) and matrices \\(A \\in \\mathbb{R}^{d1 \\times R}\\), \\(B \\in \\mathbb{R}^{R \\times d2}\\), compute the transformation of vector \\(x \\in \\mathbb{R}^{d1}\\) as:</p> \\[x' = (xW + (xA)B)^\\top\\]","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#sparse-mlp-methods","title":"Sparse MLP Methods","text":"<ol> <li> <p>Sparse Autoencoder (an MLP with an overcomplete[8x, 16x, 32x] up projection space with an L1 penalty) meant to reconstruct activations (can be anywhere; commonly residual stream, MLP activations)</p> </li> <li> <p>Transcoders: map \\(MLP_{in}\\) to \\(MLP_{out}\\) with a sparse up_projection</p> </li> </ol>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-24/#levels-of-abstraction","title":"Levels of Abstraction","text":"<ol> <li>Attention Circuits</li> <li>Feature Graphs (subgraph of Attribution Graphs)</li> <li>Neurons (problematic because polysemantic)</li> <li>Attention Head / MLP </li> </ol>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-25/","title":"2026-01-25 | Thesis Proposal","text":"<p>Goal: Propose Master's Thesis | SPAR Code Signal</p> <p>Summary: Finished SPAR Code Signal and wrote proposal of thesis in Latex</p> <p>Work sessions</p> In Out 11:00 12:30 16:30 17:20 19:50 20:20 <ul> <li>Completed SPAR Code Signal</li> </ul>","tags":["Paper Reading","Thesis"]},{"location":"dlog/2026-01-29/","title":"2026-01-29 | Recursion Reading Group","text":"<p>Goal: Kickoff Neural Network/Safety Group</p> <p>Summary: Introduce Emergent Misalignment Papers | Scaffold MNIST nn Project</p> <p>Work sessions</p> In Out 19:30 21:00","tags":["Reading Group"]},{"location":"dlog/2026-01-29/#relevant-papers","title":"Relevant Papers","text":"<ul> <li>Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs</li> <li>Natural Emergent Misalignment from Reward Hacking in Production RL</li> <li>Reward Hacking Boat</li> <li>NATURAL EMERGENT MISALIGNMENT FROM REWARD HACKING IN PRODUCTION RL</li> <li>To end on a positive note: Research Using Interpretability to Identify a Novel Class of Alzheimer's Biomarkers</li> </ul>","tags":["Reading Group"]},{"location":"dlog/2026-01-30/","title":"2026-01-30 | SPAR Interview + Thesis Work","text":"<p>Goal: SPAR Interview | Thesis work</p> <p>Summary: Dedicated quite work time</p> <p>Work sessions</p> In Out 06:00 07:00 09:00 11:30 <p>Read PERSONA VECTORS: MONITORING AND CONTROLLING CHARACTER TRAITS IN LANGUAGE MODELS</p>","tags":["Linear Algebra","Eigenvectors","Thesis"]},{"location":"dlog/2026-01-31/","title":"2026-01-31 | SPAR Interview + Thesis Work","text":"<p>Goal: CodeSignal Prep</p> <p>Summary: Use Claude Code to generate realistic CodeSignal practice environments</p> <p>Work sessions</p> In Out 08:00 08:30 16:15 17:30 20:15 21:00 <ul> <li>Giving Claude a spin, so far, really liking its abilities, especially in Coding</li> </ul> Claude System Prompt <p>Syntax by Day, Silicon by Night, I'm a Computational Linguist interested in approaching AI Safety--specifically Mechanistic Interpretability--through the lens of the language processing of Machine and Man.</p> <p>I have a bit of a non-traditional background. I have taken courses in Computer Science and Linguistics, however my math background is completely home-brewed. Assume that my math knowledge always needs to be derived from first principles, intuitions, formulas, and finally why those formulas make sense with the intuition we build.</p> <p>Please always explain from first principles with smaller toy examples before building up to the generalized form unless explicitly told.</p> <p>I also enjoy handouts written in Latex with the TikZ package. If you are going to make a Latex handout, please start with the high level motivations, use numerical examples, create colorful boxes, flowcharts and diagrams, and callouts for important key ideas and generalized formulas.</p>","tags":["CodeSignal"]},{"location":"dlog/2026-02-01/","title":"2026-02-01 | CodeSignal Prep + AutoInterp Prep","text":"<p>Goal: CodeSignal Prep + AutoInterp Prep</p> <p>Summary: </p> <p>Work sessions</p> In Out 09:00 12:00 13:55 14:50 17:45 20:00 Some Reflection <ul> <li> <p>Balancing classes and doing AI research is a little bit difficult but figuring out a good rhythm! (I honestly love all my classes so I think it's time for me to find a way to prioritize things; especially the classes I'm taking pass no pass haha!)</p> </li> <li> <p>As a personal note, I will have to get over my silly infatuation with getting a 4.0 when graduating this semester. Honestly, talking to two of my really good friends, this past Friday reminded me of the joys of senior year--yes to work hard and continue building your skills but also to enjoy being an <code>LA tourist</code> for a bit. I will try my best to let go of the proxy that is grades, and remember why I do what I do--it's definitely not for some 8-bit ASCII character on a slow loading USC academics page at the end of May.</p> </li> <li> <p>I've been waking up quite early (5am-7am) but I think I'm going to promise to myself this semester no all nighters; sure 5am wakeup is ok but not some pseudo sleep at 3am on the tables of Leavey Library (I'm sure it's not that deep)</p> </li> <li> <p>All right, now that Claude Code is finished with the next coding practice, it's time for me to get back to work</p> </li> </ul> <ol> <li>Finished reviewing <code>practice1</code> environment and finished <code>practice2</code></li> <li><code>practice3</code></li> <li>MATS CodeSignal</li> </ol>","tags":["CodeSignal","AutoInterp"]},{"location":"dlog/2026-02-02/","title":"2026-02-02 | AutoInterp Agenda 2026 Meeting","text":"<p>Goal: AutoInterp Agenda, Barez 2026 Meeting</p> <p>Summary: Meeting with Prof. Barez on Interp Agneda; Feedback on flowchart and UX</p> <p>Work sessions</p> In Out 08:00 10:00","tags":["Meeting","AutoInterp"]},{"location":"dlog/2026-02-03/","title":"2026-02-03 | Recursion Reading Group","text":"<p>Goal: Lead Recursion Reading Group: Review Tracing the Thoughts of a Large Language Model</p> <p>Summary: Prepared MNIST MLP for classification. Realized that we need to pivot to something more accessible, maybe read AI 2027 next week?</p> <p>Work sessions</p> In Out 20:00 21:00","tags":["Recursion Reading Group"]},{"location":"dlog/2026-02-04/","title":"2026-02-04 | Predictive Concept Decoders","text":"<p>Goal: Review Predictive Concept Decoders</p> <p>Summary: Review PCDs through Claude generated handouts, prepare for weekend sprint</p> <p>Work sessions</p> In Out 23:00 23:10","tags":["AutoInterp","Predictive Concept Decoders"]},{"location":"dlog/2026-02-05/","title":"2026-02-05 | Maxwell Project","text":"<p>Goal: Eigenvectors and Spectrum</p> <p>Summary: Learning about Maxwell's Equations for Language Processing in LLMs</p> <p>Work sessions</p> In Out 08:15 08:45 12:35 13:15 14:40 16:00 <ul> <li>Recently codenamed my thesis project to \"Maxwell\". Maxwell united electricity and magnetism. I hope that Professor Iskarous and I can unite the continuous vector space world of LLMs to the symbolic, hierarchical and compositional world of linguistics!</li> </ul>","tags":["Eigenvectors","Maxwell"]},{"location":"dlog/2026-02-06/","title":"2026-02-06 | Maxwell Project","text":"<p>Goal: Understand Laplacian as Mean Value Operator | Read PCD Paper</p> <p>Summary: Deep Dive on how Path Graphs generate Second Derivatives | Read Section 3 of PCD paper</p> <p>Work sessions</p> In Out 10:30 11:45 21:00 21:45 <ul> <li>Extracted the Eigenvalue spectrum for the Dyck Language Context Free Grammar</li> </ul>","tags":["Eigenvectors","Maxwell","PCD"]},{"location":"dlog/2026-02-07/","title":"2026-02-07 | Building PCD on a Student Budget","text":"<p>Goal: Building PCD on a Student Budget: docs</p> <p>Summary: Big day at the library! Understood PCD paper and started implementation; aimed to do with minimal AI Assistance</p> <p>Work sessions</p> In Out 10:00 19:30 23:20 23:50","tags":["PCD","Paper Reproduction"]},{"location":"dlog/2026-02-12/","title":"2026-02-12 | Understand Rayleigh Quotient for Eigenvectors","text":"<p>Goal: Understand Rayleigh Quotient for Eigenvectors</p> <p>Summary: Previous days did not do documentation, will be more dilligent about documenting! Focusing on first principles intuitions for deriving eigenvalues as maximal disharmony of a graph</p> <p>Work sessions</p> In Out 14:40 15:10 20:00 20:30 22:30 22:55 <p>Super interesting! I didn't fully intuit the \\(f^\\top L f = \\sum_{(i,j) \\in E} (f_i - f_j)^2\\) but understood that the Rayleigh Quotient for a matrix \\(M\\) returns the eigenvalue when given the eigenvector as input.</p> \\[R(v ; M) = \\lambda\\] <p>where \\(v\\) is an eigenvector of \\(M\\) and \\(\\lambda\\) is the corresponding eigenvalue.</p> <p>Next step tomorrow is to fully gain intuition on the meaning of the Rayleigh Quotient applied to the Laplacian matrix.</p>","tags":["Maxwell"]},{"location":"dlog/2026-02-13/","title":"2026-02-13 | Deriving Rayleigh Equations","text":"<p>Goal: Weekly Research Meeting with Jonathan</p> <p>Summary: Derive the Rayleigh equation from first principles with Jonathan (edge vs. node centric)</p> <p>Work sessions</p> In Out 14:00 15:00 <p>Prove with Jonathan that the third eigenvector for the Path Graph may be monotonically increasing as well.</p>","tags":["Maxwell"]},{"location":"dlog/2026-02-16/","title":"2026-02-16 | Star and Path Spectrums","text":"<p>Goal: Extract Spectrums and Eigenvectors for Star and Path Graphs</p> <p>Summary: Documented tasks to do, punting completion to tomorrow</p> <p>Work sessions</p> In Out 15:00 15:20 <p>Actionable Items:</p> <ul> <li> <p> <code>get_rayleigh_quotient(vec: Float[Tensor, \"n\"], laplacian: Float[Tensor, \"n n\"]) -&gt; Float[Tensor, \"\"]</code>; function which </p> </li> <li> <p> Plot eigenvectors in addition to eigenvalues</p> </li> <li> <p> Create the parent class <code>Graph</code> and three child classes <code>PathGraph</code>, <code>StarGraph</code>, <code>DyckGraph</code>; each support creating a specific type of graph and the <code>get_adjacency_matrix</code> function</p> </li> <li> <p> Visually compare each of the classes of graphs</p> </li> <li> <p> Use Claude to create a UI which allows you to easily:   (a) Create a type of graph (e.g. <code>PathGraph</code>) and save the graph to a .txt for uploading   (b) Visualize the graph topology   (c) See the eigenvalue spectrum   (d) select an eigenvector to plot and its values get imposed onto the graph topology on (b) with edges annotated with difference betwen nodes   (e) unselect and view just topology</p> </li> </ul> <p>I'm heavily included to use an AI coding assitant (Claude Code) only for the last portion to make sure my logic is correct</p>","tags":["Maxwell"]},{"location":"dlog/2026-02-17/","title":"2026-02-17 | Star and Path Spectrums","text":"<p>Goal: Extract + Visualize Eigenvalue Spectrums, Eigenvectors, and Topology for Star and Path Graphs</p> <p>Summary: Visualizations and Graph Type Extractions (Dyck Graphs WIP)</p> <p>Work sessions</p> In Out 14:30 17:20 <p>Actionable Items:</p> <ul> <li> <p> <code>get_rayleigh_quotient(vec: Float[Tensor, \"n\"], laplacian: Float[Tensor, \"n n\"]) -&gt; Float[Tensor, \"\"]</code>; function which </p> </li> <li> <p> Plot eigenvectors in addition to eigenvalues</p> </li> <li> <p> Create the parent class <code>Graph</code> and three child classes <code>PathGraph</code>, <code>StarGraph</code>, <code>DyckGraph</code>; each support creating a specific type of graph and the <code>get_adjacency_matrix</code> function</p> </li> <li> <p> Visually compare each of the classes of graphs</p> </li> <li> <p> Use Claude to create a UI which allows you to easily:   (a) Create a type of graph (e.g. <code>PathGraph</code>) and save the graph to a .txt for uploading   (b) Visualize the graph topology   (c) See the eigenvalue spectrum   (d) select an eigenvector to plot and its values get imposed onto the graph topology on (b) with edges annotated with difference betwen nodes   (e) unselect and view just topology</p> </li> </ul> <p>I'm heavily included to use an AI coding assitant (Claude Code) only for the last portion to make sure my logic is correct</p>","tags":["Maxwell"]},{"location":"dlog/2026-02-18/","title":"2026-02-18 | Dyck Graphs + Interpret Spectrums","text":"<p>Goal: Support Dyck Graphs + Understand Fully Connected/Star/Dyck Spectra</p> <p>Summary: Finish visualization of Graph Types</p> <p>Work sessions</p> In Out 08:00 10:00 <p>Actionable Items:</p> <ul> <li> <p> Create the parent class <code>Graph</code> and three child classes <code>PathGraph</code>, <code>StarGraph</code>, <code>DyckGraph</code>; each support creating a specific type of graph and the <code>get_adjacency_matrix</code> function</p> </li> <li> <p> Understand Path Graph, Fully Connected Graph, Star Graph, and Dyck Graph Spectra</p> </li> </ul>","tags":["Maxwell"]},{"location":"dlog/2026-02-20/","title":"2026-02-20 | Dyck Graphs + Interpret Spectrums","text":"<p>Goal: Understand Path, Full, and Dyck Spectra and Eigenvectors</p> <p>Summary: </p> <p>Work sessions</p> In Out 13:07 07:20 <p>Actionable Items:</p> <ul> <li> Understand Path Graph, Fully Connected Graph, Star Graph, and Dyck Graph Spectra</li> </ul>","tags":["Maxwell"]},{"location":"dlog/2026-02-24/","title":"2026-02-24 | Circuits + Documentation","text":"<p>Goal: Read up on Feature Splitting + Update ReadMe and Add Documentation for Eigen Spectrums</p> <p>Summary: Understand failure mode of Feature Absorption/Splitting in Attribution Graphs</p> <p>Work sessions</p> In Out 13:07 07:20 <p>Recover from being sick!</p>","tags":["Maxwell","Circuits"]},{"location":"notes/References/","title":"Reference Links","text":"<p>Adding links I run into that I think can be helpful later in the journey</p>"},{"location":"notes/References/#ai-safety","title":"AI Safety","text":"<ol> <li>Neel Nanda's Glossary</li> </ol>"},{"location":"notes/References/#math","title":"Math","text":"<ol> <li> <p>StatQuest with Josh Starmer; see StatQuest Statistics Lessons</p> </li> <li> <p>Resources Section from CSCI-467 Introduction to Machine Learning</p> <ul> <li>I took this class in Fall 2024 with Prof. Jieyu Zhao with the course designed and resources compiled by Prof. Robin Jia. Big thanks to both of them for their guidance!</li> </ul> </li> </ol>"},{"location":"notes/References/#math-concepts","title":"Math Concepts","text":"<ul> <li>Probability and Statistics<ul> <li>Probability Distributions [StatQuest Video]</li> <li>Normal Distributions [StatQuest Video]</li> <li>Mean, Variance, Std Deviation [StatQuest Video]</li> <li>Mathematical Models [StatQuest Video]</li> <li>Covariance [StatQuest Video]</li> <li>Conditional Probabilities [StatQuest Video]</li> <li>Bayes Theorem [StatQuest Video]</li> <li>Expected Value <ul> <li>Discrete [StatQuest Video]</li> <li>Continuous [StatQuest Video]</li> </ul> </li> <li>Central Limit Theorem [StatQuest Video]</li> </ul> </li> </ul>"},{"location":"notes/References/#interesting-papers","title":"Interesting Papers","text":"<ul> <li>Evaluating honesty and lie detection techniques on a diverse suite of dishonest models</li> </ul>"},{"location":"notes/Todo/","title":"Running Todo List","text":""},{"location":"notes/Todo/#math","title":"Math","text":"<ul> <li> [Added 2025-12-30] Area Under Curve (AUC) and Receiver Operating Characteristic (ROC) Test</li> <li> [Added 2025-12-30] Wilcoxon Signed-Rank Test</li> <li> Go through StatQuest Statistics Lessons<ul> <li> [Completed 2025-10-27] [Added 2025-10-25] Probability Distributions [StatQuest Video]</li> <li> [Completed 2025-10-27] [Added 2025-10-25] Normal Distributions [StatQuest Video]</li> <li> [Added 2025-10-25] Mean, Variance, Std Deviation [StatQuest Video]</li> <li> [Added 2025-11-03] (n-1) vs. (n) in estimate of population variance [StatQuest Video]</li> <li> [Added 2025-10-25] Mathematical Models [StatQuest Video]</li> <li> [Added 2025-10-25] Covariance [StatQuest Video]</li> <li> [Added 2025-10-25] Conditional Probabilities [StatQuest Video]</li> <li> [Added 2025-10-25] Bayes Theorem [StatQuest Video]</li> <li> [Added 2025-10-25] Expected Value <ul> <li> [Added 2025-10-25] Discrete [StatQuest Video]</li> <li> [Added 2025-10-25] Continuous [StatQuest Video]</li> </ul> </li> <li> [Added 2025-10-25] Central Limit Theorem [StatQuest Video]</li> </ul> </li> </ul>"},{"location":"notes/Todo/#information-theory","title":"Information Theory","text":"<ul> <li> [Added 2025-10-27] Surprisal vs. Perplexity vs. Entropy vs. Cross-Entropy</li> </ul>"},{"location":"notes/Todo/#mechanistic-interpretability","title":"Mechanistic Interpretability","text":"<ul> <li> [Added 2025-10-21] Learn ARENA curriculum</li> </ul>"},{"location":"notes/Todo/#seminal-mech-interp-papers","title":"Seminal Mech Interp Papers","text":"<ul> <li> [Added 2026-01-18] Toy Models of Superposition</li> <li> [Added 2026-01-18] Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</li> <li> [Added 2026-01-18] Circuit Tracing: Revealing Computational Graphs in Language Models</li> </ul>"},{"location":"notes/Todo/#mech-interp-concepts-to-master","title":"Mech Interp Concepts to Master","text":"<ol> <li>From IOI Paper: (1) Logit, Head, Layer Attribution, Logit Diffs (2) Activation Patching (3) Path Patching</li> </ol>"},{"location":"notes/Todo/#mech-inter-safety-application","title":"Mech Inter Safety Application","text":"<ul> <li> [Added 2026-01-18] Refusal Direction is Universal Across Safety-Aligned Languages</li> <li> [Added 2026-01-18] LLMs Encode Harmfulness and Refusal Separately</li> </ul>"},{"location":"notes/Todo/#automated-circuit-discovery","title":"Automated Circuit Discovery","text":"<ul> <li> [Added 2026-01-19] Transformer Circuit Faithfulness Metrics are not Robust, response to ACDC</li> <li> [Added 2026-01-19] Towards Automated Circuit Discovery for Mechanistic Interpretability</li> </ul>"},{"location":"notes/Todo/#interp-for-monitoringcontrol","title":"Interp for Monitoring/Control","text":"<ul> <li> [Added 2026-01-19] Building Production-Ready Probes For Gemini</li> </ul>"},{"location":"notes/Todo/#rl","title":"RL","text":"<ul> <li> [Added 2026-01-30] A Case for Model Persona Research; thanks to Daniel Tan for sharing this at LISA during the Evan Hubinger talk</li> <li> [Added 2026-01-30] PERSONA VECTORS: MONITORING AND CONTROLLING CHARACTER TRAITS IN LANGUAGE MODELS</li> </ul>"},{"location":"notes/Todo/#reading","title":"Reading","text":"<ul> <li> [Added 2025-12-01] How Can Interpretability Researchers Help AGI Go Well? to reading list</li> <li> [Added 2025-10-27] From OpenAI Scheming Blog, Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety</li> <li> [Added 2025-10-26] Download and annotate March 27th, 2025 Circuit Tracing: Revealing Computational Graphs in Language Models<ul> <li> [Added 2025-10-26] Perhaps try to reproduce on a smaller model?</li> <li> Additional reference: [Added 2025-10-26] On the Biology of a Large Language Model</li> </ul> </li> <li> [Added 2025-10-25] Read Tracing the thoughts of a large language model</li> <li> [Added 2025-10-21] Read Progress measures for grokking via mechanistic interpretability by Nanda et al.</li> <li> [Added 2025-10-21] Look into reproducing Progress measures for grokking via mechanistic interpretability by Nanda et al.</li> </ul>"},{"location":"notes/Todo/#documentation","title":"Documentation","text":"<ul> <li> [Added 2025-10-24] Add section on current project (Dyck Interp Probe)</li> <li> [Completed 25-10-23] Document 25-10-17 to 25-10-20 range of progress</li> </ul>"},{"location":"notes/concepts/stats_and_probability_concepts/","title":"Stats and Probability Concepts","text":""},{"location":"notes/concepts/stats_and_probability_concepts/#distributions","title":"Distributions","text":"Probability Distributions"},{"location":"notes/concepts/stats_and_probability_concepts/#definitions","title":"Definitions","text":"<ul> <li>Histogram: Discrete plot where x-axis is buckets of a measurement (e.g. heights from 5' to 5.5') and y-axis is the count of the number of measurements (e.g. number of people between 5' to 5.5')<ul> <li>In some ways, this is like a C++ array where index is the quantity we want to measure and the value in that index is the frequency count </li> <li>Here we see the discretized bins; we see the distribution show most height are around 5'-6'</li> <li>We would say the probability distribution is centered around the 5'-6' bins and that seeing a 5'-5.5' person has the greatest probability<ul> <li>If we were to pick a person at random, there is the highest probability that that person is from bin 5'-5.5'</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/papers/information-theory/UID/","title":"Revisting the Uniform Information Density Hypothesis","text":"<p>Authors: Clara Meister, Tiago Pimentel, Patrick Haller, Lena J\u00e4ger, Ryan Cotterell, Roger Levy</p> <p>Publication Date: 2021-09-23</p> <p>Full Paper: Revisiting the Uniform Information Density Hypothesis</p> <ul> <li>See UID as a signal smoothing of effort or a regression to the mean of a targtet information rate</li> <li>Complicated by Global vs local UID (e.g. UID as minimizing word to word variability or total deviation from the mean)</li> </ul>"},{"location":"notes/papers/information-theory/UID/#surprisal","title":"Surprisal","text":"Surprisal <ul> <li>Given a signal \\(\\textbf{u} = \\lang u_1, u_2, ... u_N \\rang\\)</li> <li>\"Surprisal is the negative log prob of the unit conditioned on its prior context\" $$ \\text{surprisal of unit n} = s(u_n) = - \\log p(u_n | \\textbf{u}_{&lt;n}) $$</li> </ul>"},{"location":"notes/papers/information-theory/UID/#effort","title":"Effort","text":"Effort \\[ \\text{Effort} (u_n) \\propto  s(u_n) \\] <ul> <li> <p>Problematic definition below shows that individual surprisal is not incentivized to distribute information in an utterance $$ \\text{Effort} (\\textbf{u}) \\propto  \\sum^N_{n=1} s(u_n) $$</p> </li> <li> <p>This paper proposes a (1) super-linear (greater than linear) function of surprisal which is (2) linear to utterance length $$ \\text{Effort} (\\textbf{u}) \\propto  \\sum^N_{n=1} s(u_n)^k + c \\cdot N$$</p> <p>where $ c &gt; 0 $ and $ k &gt; 1 $</p> </li> </ul>"},{"location":"notes/papers/information-theory/UID/#uid-scope-global-vs-local","title":"UID Scope (Global vs. Local)","text":"<ol> <li>S1 (Red) has better Global UID (relative to a specific mean information rate)<ul> <li>\"as information content per word varies less\u2014in absolute terms\u2014across the sentence\"</li> </ul> </li> <li>S2 (Blue) has better Local UID since there are no big jumps in information rate between consecutive words<ul> <li>\"interpret UID as a pres- sure to avoid rapidly shifting from information dense (and therefore cognitively taxing) sections to sections requiring minimal processing effort\"</li> </ul> </li> </ol> Global UID <ul> <li>UID applied globally to a target mean information rate<ul> <li>Some researchers propose that a universal channel rate exists $$ UID^{-1} = \\frac{1}{N} \\sum^N_{n=2} \\Delta (s(u_n), \\mu _c)$$ </li> </ul> </li> </ul> Local UID \\[ UID^{-1} = \\frac{1}{N-1} \\sum^N_{n=2} \\Delta (s(u_n), s(u_{n-1}))\\]"},{"location":"notes/papers/interpretability/ACDC/","title":"Towards Automated Circuit Discovery for Mechanistic Interpretability","text":"<p>Authors: Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, Adri\u00e0 Garriga-Alonso</p> <p>Publication Date: 2023-10-28</p> <p>Full Paper: Towards Automated Circuit Discovery for Mechanistic Interpretability</p> <p>In Progress Reproduction: Github Repo</p>"},{"location":"notes/papers/interpretability/ACDC/#notes","title":"Notes","text":""},{"location":"notes/papers/interpretability/ACDC/#keywords","title":"Keywords","text":"<ol> <li> <p>Mech Interp -&gt; \"reverse-engineering model components into human-understandable algorithms\"</p> </li> <li> <p>Models = Computational Graphs to perform a task, circuits = \"subgraphs with distinct functionality\"</p> </li> </ol>"},{"location":"notes/papers/interpretability/Automated-Interpretability-Agendas/","title":"Automated Interpretability Agenda","text":"<p>Flowchart and summarization of ideas + 2 ideas for use cases from Fazl Barez's Automated Interpretability Agenda 2026</p> <p>Original Paper: Automated Interpretability-Driven Model Auditing and Control: A Research Agenda</p> <p></p> Thoughts on Automated Interpretability Agenda (Barez 2026) <p>Response to MATS Summer 2026 application question on an <code>underrated</code> idea in Empirical AI Safety research.</p> <p>Automated Interpretability has strong promise to catalyze interpretability from a descriptive tool of current model behavior to a robust predictive pipeline to monitor, control, and permanently intervene on increasingly powerful models. The 3-step agentic system in Automated Interpretability-Driven Model Auditing and Control: A Research Agenda [Barez 2026] allows domain experts to interact with </p> <p>(a) target frontier model, </p> <p>(b) decode internal activations into natural language via an investigator model a la LatentQA [Pan et al. 2024], Activation Oracles (AO) [Karvonen et al. 2025], Predictive Concept Decoders (PDC) [Huang et al. 2025], and </p> <p>(c) update model weights to reflect domain expert judgements and verify changes using causal intervention.</p> <p>I argue that Automated Interpretability agenda is underrated because in addition to pipelines that can monitor CoT faithfulness [Barez et al. 2025] and detect/control emerging model maligned behavior during training with scale (\u201cbitter lesson\u201d style), I also argue that this system can accelerate Safety research racing against soon-to-be agentic Capabilities research while building trust and intuition with non-technical audiences. For example AutoInterp can:</p> <p>(1) accelerate/verify existing interpretability research such as facilitating end-to-end agent driven causal intervention experiments; step (b) from above could detect whether a model\u2019s harmfulness refusal is using the universal refusal direction [Wang et al. 2025] or an independent harmfulness steering vector [Zhao et al. 2025] </p> <p>(2) increase literacy of policymakers on current AI Safety practices (e.g. policymakers can independently run causal intervention experiments through a natural language interface) to build intuition/informed decision on AI governance (e.g. California Senate Bill 53) [SB-53]</p> <p>(3) build trust and intuitions of general users of AI systems (e.g. teens using AI systems for therapy/education can verify underlying reasoning for model responses)</p> <p>Essentially, Automated Interpretability\u2019s 3-step agentic pipelines have the potential to transform interpretability from a bespoke art, to a scalable science that mitigates x-risk by empowering human engagement and trust of safety in AI systems.</p> <p>References:</p> <p>Automated Interpretability-Driven Model Auditing and Control: A Research Agenda [Barez 2026]</p> <p>LatentQA: Teaching LLMs to Decode Activations Into Natural Language [Pan et al. 2024]</p> <p>Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers [Karvonen et al. 2025]</p> <p>Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants [Huang et al. 2025]</p> <p>LLMs Encode Harmfulness and Refusal Separately [Zhao et al. 2025]</p> <p>Refusal Direction is Universal Across Safety-Aligned Languages [Wang et al. 2025]</p> <p>Chain-of-Thought Is Not Explainability [Barez et al. 2025]</p> <p>California Senate Bill 53 [SB-53]</p>"},{"location":"notes/papers/interpretability/Neo_et_al_2024/","title":"Interpreting Context Look Ups","text":"<p>Authors: Clement Neo, Shay B. Cohen, Fazl Barez</p> <p>Publication Date: 2024-10-23</p> <p>Full Paper: Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions</p> <p>In Progress Reproduction: Github Repo</p>"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#summary","title":"Summary","text":"<p>This paper aims to bridge the gap between MLP and Attention Interpretability by focusing on (1) identifying next-token neurons and (2) find which attention heads activate that neuron.</p> <p>Limitation: The paper only focuses on single words and single neurons; future work could consider more complex neural firing patterns</p> <p>Working on trying to reproduce this paper, we will focus on using GPT-2 small (though the paper also uses GPT-2 Large and Pythia as well)</p> <p>See handwritten notes/derivations (section Reproducing Neo et al. 2024) for drawings of matrices / geometric intuition</p>"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#high-level-pipeline","title":"High Level Pipeline","text":"<ol> <li>Identify next-token neurons; find prompts that highly activate them</li> <li>Determine Attention heads most responsible for activating each next-token neuron using head attribution score</li> <li>Use GPT-4 to generate explanations for activity patterns of these attention heads</li> <li>Evaluate response quality by using GPT-4 zero shot classifier for head activity on a new prompt </li> </ol>"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#section-41-identifying-next-token-neurons-and-mlp-interpretability","title":"Section 4.1: Identifying Next-token Neurons and MLP Interpretability","text":""},{"location":"notes/papers/interpretability/Neo_et_al_2024/#mlp-architecture","title":"MLP Architecture","text":"MLP Algorithm <p>let Up Projection Weight Matrix $ = W_{up} \\in \\mathbb{R}^{d_{up}, d_{model}}$</p> <p>let Down Projection Weight Matrix $ = W_{down} \\in \\mathbb{R}^{d_{model}, d_{up}}$</p> <p>let Activation Function $ \\sigma = GELU $ ReLU but more differentiable</p> <p>let biases = \\(b_{up} \\in \\mathbb{R}^{d_{up}}\\) and \\(b_{down} \\in \\mathbb{R}^{d_{down}}\\)</p> \\[ MLP(h) = W_{down} \\sigma(W_{up} h + b_{up}) + b_{down} \\in \\mathbb{R}^{d_{model}}\\] <p>Note that <code>MLP(h)</code> must be in \\(\\mathbb{R}^{d_{model}}\\) since it is written back to the \"working memory\" Residual Stream</p>"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#next-token-neuron-algorithm","title":"Next-Token Neuron Algorithm","text":"<p>I like to call this part the \"Secret Life of a Hidden Neuron\" (also known as finding the <code>next-token neuron</code>). This consists of three steps:</p> <ol> <li>Feature Weighting (Reading from Residual Stream)</li> <li>Down Projection Matrix Columns as Information (Writing to Residual Stream)</li> <li>Next-token neuron as max congruence between information and unembedding</li> </ol> Concept 1: Feature Weighting <p>To find the <code>next-token neuron</code> \\(a_i\\) or weight of information vector \\(W_{down}[:,i]\\), we calculate \\(a\\):</p> \\[a = \\sigma(W_{up} h + b_{up}) \\in \\mathbb{R}^{d_{up}}\\] <ol> <li> <p>Crucially, the consequence of the formula is that \\(a_i = \\langle W_{up}[i], h \\rangle\\)</p> <p>a. The row \\(W_{up}[i]\\) helps us to compute the \"gating neuron\" \\(a_i\\)</p> <p>b. \\(W_{up}[i]\\) \"reads\" from the Residual Stream</p> </li> <li> <p>Each weight \\(a_i\\)<code>decides to include</code>/<code>gates</code>/<code>weights</code> a specific information basis vector \\(W_{down}[:,i] \\in \\mathbb{R}^{d_{model}}\\) to be passed onto the Residual Stream \\(h\\)</p> </li> <li>There are \\(d_{up}\\) features to weigh; high dimensionality \\(d_{up}\\) allows the model to store \\(d_{up}\\) \"vectors of information\"</li> </ol> Concept 2: \\(W_{down}[:,i]\\) as information basis vectors <p>In this section, we assume the following interpretation of matrices (based on 3Blue1Brown Change of basis | Chapter 13, Essence of linear algebra):</p> <ol> <li>Matrices encode linear transformations </li> <li> <p>The columns of a matrix are being basis vectors of <code>Source Space (SS)</code> expressed in <code>Target Space (TS)</code></p> <p>a. A basis vector \\(b\\) defines how a <code>SS</code> vector component along axis \\(b\\) should stretch/transform in <code>TS</code> (see handwritten notes for visual intuition)</p> </li> </ol> <p>Interpretation of basis vectors as encoding information:</p> <ol> <li>Matrix \\(W_{down} \\in \\mathbb{R}^{d_{model}, d_{up}}\\) has \\(d_{up}\\) basis vectors in <code>TS</code> (we can call this <code>MLP space</code> if we like) from <code>SS</code> \\(d_{model}\\) (we can call this <code>Residual space</code> if we like)</li> <li>Each column \\(W_{down}[:,i]\\) is a basis vector in <code>MLP space</code> representing potential information to add to \\(h_k\\) in the Residual Stream of layer \\(k\\)</li> <li>\\(a_i\\) <code>chooses</code> which information basis vectors \\(W_{down}[:,i]\\) should be added to add to \\(h_k\\) in the Residual Stream</li> </ol> <p>The update from the previous Residual Stream \\(h_{k}\\) to the new Residual Stream \\(h_{k+1}\\) is mathematically expressed as the weighted sum of all the \\(d_{up}\\) potential information to include:</p> \\[h_{k+1} = \\sum_{i=1}^{d_{up}} a_i \\cdot W_{down}[:,i] \\] Concept 3: Next-token Neuron = Max Congruence Score <p>Armed with an understanding of \\(a_i\\) \\(W_{down}[:,i]\\) and $ W_{up}[i]$, we define the <code>potential</code> for a neuron \\(a_i\\) to activate token \\(t\\) as \\(s_i\\):</p> \\[ s_i = \\underset{t \\in \\mathbb{V}}{max} \\langle W_{down}[:, i], e^{(t)} \\rangle \\] <p>where \\(e^{(t)}\\) = the unembedding vector for token \\(t\\) LLM Basics: Embedding Spaces - Transformer Token Vectors Are Not Points in Space by AI Alignment Forum has a very nice introduction with vocabulary \\(\\mathbb{V}\\)</p> <p>Since \\(s_i\\) is not dependent on the activation/\"neuron firing\" of \\(a_i\\), \\(s_i\\) represents the congruence of the information basis vector \\(W_{down}[:, i]\\) with the unembedding \\(e^{(t)}\\) if the neuron were to \"fire\".</p> <p>Thus, the next-token neuron for a token \\(t\\) is the largest \\(i\\) with the largest \\(s_i\\) mathematically expressed as:</p> \\[ \\text{next-token neuron for token t} = \\underset{i \\in 1:d_{up}}{argmax} (s_i)\\]"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#summary-table-math-interpretation","title":"Summary Table: Math + Interpretation","text":"Math Interpretation \\(W_{up}[i]\\) <code>Read</code>/<code>feature extract</code> from Residual Stream \\(h_k\\) and decide whether or not to activate information in \\(W_{down}\\) \\(W_{down}[:, i]\\) Information to add to the residual stream \\(h_{k+1}\\) \\(\\langle a_i, W_{down}[:, i] \\rangle\\) <code>Gate</code>/<code>weight</code>/<code>how much</code> of information from \\(W_{down}[:,i]\\) \\(h_{k+1}\\) Weighted sum of information, \\(W_{down}[:, i]\\) to add to residual stream \\(s_i\\) Congruence between information in \\(W_{down}[:, i]\\) and unembedding vector for token \\(t\\), \\(e^{(t)}\\) used to calcualte next-token neuron"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#section-42-high-activating-prompts","title":"Section 4.2: High-Activating Prompts","text":"High Level Goal (Computation Level) <p>Given a neuron \\(i\\) in the MLP of layer \\(l\\), \\(n_{l, i}\\): - Find the maximum activating set of contexts/prompts \\(P\\)</p> <p>Intuition</p> <ol> <li>We developed the algorithm for Next-token neurons above</li> <li>For each neuron, we want to find the context where the neuron does lots of work/<code>fires</code>/<code>activates</code></li> <li>Next steps: given a prompt \\(p\\) from \\(P\\), go through \\(p\\) token by token and see if \\(n_{l,i}\\) is activated</li> </ol> \\(\\phi (p; l, i)\\) Algorithm: Prompt Neuron Activation <p>let \\(n_{(l,i)}\\) = neuron \\(i\\) of layer \\(l\\)</p> <p>let prompt \\(p\\) of length \\(T\\) = \\((x_1, x_2, x_3, ..., x_T)\\); we will use \\(t\\) to represent a token in \\(p\\)</p> <p>\\(\\phi (p; l, i)\\) is the maximum activation of the specific neuron \\(n_{(l,i)}\\) in the prompt \\(p\\). We can imagine:</p> <ol> <li>Running a forward pass with prompt \\(p\\) </li> <li>Each token \\(t\\) in \\(p\\) is like a <code>flip book</code>/<code>z-axis</code> (we can imagine holding a magical push pin on that \\(n_{(l,i)}\\) as we flip the page \\(t\\))</li> <li>Take the token that maximally activates the neuron \\(n_{(l,i)}\\)</li> </ol> <p>Mathematically, this <code>flip book</code> and <code>push pin</code> is represented as:</p> \\[\\phi (p; l, i) = \\underset{t \\in p}{max}  ( a_{(l, i)}^{(t)} )\\]"},{"location":"notes/papers/interpretability/Neo_et_al_2024/#section-43-individual-head-attribution","title":"Section 4.3: Individual Head Attribution","text":"Chain of Activations <p>Given a next-token neuron \\(i\\) at layer \\(l\\):</p> <ol> <li>The definition of a next-token neuron is that the \\(i\\) chosen has max \\(s_i\\) for all tokens</li> <li>Max \\(s_i\\) means max </li> </ol>"},{"location":"notes/papers/interpretability/Scheming_OpenAI_Apollo_2025-09-17/","title":"Detecting and reducing scheming in AI models","text":"<p>Authors: OpenAI and Apollo Research</p> <p>Publication Date: 2025-09-17</p> <p>Full Paper: Stress Testing Deliberative Alignment for Anti-Scheming Training</p> <p>Open AI Blog: Detecting and reducing scheming in AI models</p>"},{"location":"notes/papers/interpretability/Scheming_OpenAI_Apollo_2025-09-17/#key-terms","title":"Key Terms","text":"<ul> <li>Scheming<ul> <li>\"Pretending to be aligned while pursuing some other agenda\"</li> <li>From output alone is not possible to see if models are deliberately being unfaithful</li> <li>My definition: Scheming is when an AI model deliberately responds (either correctly or incorrectly) to a user to pursue an unaligned goal.</li> </ul> </li> <li>Covert Actions<ul> <li>\"deliberate witholding or distortion of task-relevant information\"</li> <li>Proxy for scheming </li> <li>When a model makes its answers sound more aligned to a human goal by purposefully distorting its answers</li> </ul> </li> <li>Sandbagging<ul> <li>When a model purposefully underperforms to achieve an unaligned task</li> </ul> </li> <li>Deception<ul> <li>Model pretends to have completed a task without actually doing so <ul> <li>e.g. iconic example of reading a large CSV file and responding before processing</li> </ul> </li> </ul> </li> <li>Situational Awareness<ul> <li>Models become aware that their responses are being evaluated; dangerous for different evaluation- vs. deploy-time behavior</li> </ul> </li> <li>Deliberative Alignment<ul> <li>Teaching models to read and reason through \"anti-scheming\" rules before answering (think of an advanced Isaac Asimov's \"Big Three\" rules of robotics)</li> </ul> </li> </ul>"},{"location":"notes/papers/interpretability/Scheming_OpenAI_Apollo_2025-09-17/#main-takeaways","title":"Main Takeaways","text":"<ol> <li> <p>Reading Chain-of-thought (COT) reasoning transparency in English allows for researchers to peer into model scheming; this would fail if COT is opaque or unfaithful (see Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety)</p> </li> <li> <p>Model Anti-scheming training (through deliberate alignment) can result in either (1) model faithfullness or (2) models become better at scheming/hide misalignment</p> <ul> <li>Deliberate alignment's anti-scheming specification is meant to train model faithfullness (1) not hiding misalignment (2); supported by OpenAI model citing spec in COT reasoning</li> </ul> </li> <li> <p>Situational Awareness may allow for modesl to score well during alignment benchmarks but execute misaligned behavior in production; current impact is limited because models do not have opportunity to cause harm</p> </li> </ol> Always Inserting Situational Awareness Prompt <ul> <li>Interesting finding: Removing Situational Awareness COT increases likelihood for scheming; Adding Situational Awareness COT decreases likelihood for scheming</li> <li>Wonder if it's possible to always just add Situational Awareness in COT for production deployment;(1)perhaps models would start outsmarting this method and (2) does not solve the fundamental alignment problem</li> </ul>"},{"location":"notes/papers/interpretability/Scheming_OpenAI_Apollo_2025-09-17/#reflections","title":"Reflections","text":""},{"location":"notes/papers/interpretability/Scheming_OpenAI_Apollo_2025-09-17/#guiding-questions-from-arena","title":"Guiding Questions from ARENA","text":"<ol> <li>Why might model scheming be a particularly worrying concern as models get more capable? </li> <li>Why does situational awareness (or evaluation awareness) pose a problem for the field of model evaluations? How might we try to mitigate this?</li> <li>In your view, does this paper provide evidence for or against the following suggestion: \"Deliberative alignment will effectively work to address our concerns about scheming in LLMs.\" Justify your opinion.</li> </ol>"},{"location":"notes/projects/Dyck-probe/","title":"Dyck Transformer Probe","text":"<p>Work in progress ntoes for probing models for syntactic dependency</p> <p></p>"},{"location":"notes/projects/MultilingualSemanticsProbe/","title":"Multilingual Semantics Probe","text":"<p>Version 1: 2025-12-18 - 2026-01-03</p> <ul> <li> <p>In Progress Github Repo</p> </li> <li> <p>Executive Summary</p> </li> </ul> Timelog <p>To timebox this project, we'll follow a Nanda MATS stream style 16-20 hour project.</p> <p>Hopefully, this rigorous/pragmatic approach can lead to some ambitious outcomes in understanding model representations of the scope ambiguity phenomenon.</p> Hour Progress 0-1 Scaffold Project using GPT Project 1-2 Setup Github, generate stimuli, start understanding log probs 2-5.5 Understand log probs, vectorized logic for Continuations Log Probs 5.5-7.5 Setup aggregation/comparing Log Probs for surface vs. inverse Prompts 7.5-10.5 Debug scripts to add (1) bfloat16 support large models (&gt;27b) and (2) comparison of EN vs. ZH 10.5-12 Read Fang et al. and Schut 2025 et al., test GPT-2-Chinese (<code>uer_gpt2-xlarge-chinese-cluecorpussmall</code>), <code>aya-23-35B</code>, <code>Gemma2-27B</code>, and <code>aya-expanse-32b</code> 12-12.5 Verified that Existential-Universal and Universal-Existential prefer the same continuation preferences 12.5-13 Find that English preference for inverse and Chinese preference for surface is statistically significant (p=1.948e-18) 13 - 14 Learn and document math of Steering Vectors 14 - 15 Setback--GPT2-Chinese is unreliable 15 - 16 Qwen2.5 Surface/Inverse Scope Judgements; continue documenting Steering Vector math 17 - 20 Look for Steering Vectors"},{"location":"notes/projects/MultilingualSemanticsProbe/#high-level-summary","title":"High Level Summary","text":"<p>I am interested in investigating how (multilingual) LLMs represent <code>Quantifier Scope Ambiguity</code> cross-linguistically. </p> <p>Examples:</p> Language Sentence Expected Interpretation English A shark ate every pirate Ambiguous(1) There is exactly 1 shark (Surface Scope)(2) There are 1 or more sharks (Inverse Scope) Mandarin y\u01d2u y\u00ec ti\u00e1o sh\u0101y\u00fa ch\u012b le m\u011bi y\u00ed g\u00e8 h\u01ceid\u00e0o\u6709\u4e00\u689d\u9bca\u9b5a\u5403\u4e86\u6bcf\u4e00\u500b\u6d77\u76dc Unambiguous(2) There is exactly 1 shark (Surface Scope) Research Questions <ol> <li>Do LLMs allow for Ambiguous (Surface/Inverse) quantifier scope in English but only Surface Scope in Mandarin?</li> <li>Recent research on model size has found \"shared circuitry increases with model scale\" (Brinkmann et al. 2025); does model size impact whether an LLMs applies the correct language-specific interpretation?<ol> <li>E.g. larger models with a multi-lingual semantic space would incorrectly apply the Inverse scope to Mandarin while a small model wouldn't</li> </ol> </li> <li>Is there an interpretable hidden representation for quantifier scope? Can this be used to steer the model to get a specific interpretation in a particular language?</li> </ol> Hypothesis <p>Given a multiple-choice situation (<code>please choose exactly 1 answer, (1) there is exactly 1 shark | (2) there are 1 or more sharks</code>):</p> <ul> <li>Larger models will over-generalize English Inverse Scope semantics to Mandarin while smaller models will correctly apply language-specific semantic interpretations</li> </ul> Relevant Papers <ol> <li> <p>Scrontas et al. 2017: Cross-linguistic scope ambiguity: When two systems meet</p> <p>a. Double quantifier scope ambiguity in Mandarin-English Heritage Bilinguals</p> </li> <li> <p>Brinkmann et al. 2025: Large Language Models Share Representations of Latent Grammatical Concepts Across Typologically Diverse Languages</p> <p>a. Larger models can represent multi-lingual concepts about morphosyntactic category (even when predominantly trained on English)</p> </li> <li> <p>Claude Haiku Multilingual Circuits </p> <p>a. Section 5.6 shows that English is priviledged though multi-lingual representations do exist</p> </li> <li> <p>Fang et al. 2025: Quantifier Scope Interpretation in Language Learners and LLMs </p> <p>a. Exactly the same from Scrontas et al. 2017 applied to humans, gives insightful models to try</p> </li> <li> <p>Schut et al. 2025: Do Multilingual LLMs Think In English?</p> <p>a. Evidence that multilingual models <code>reason</code> in an English centric way</p> <p>b. Introduction to the steering vector concept</p> </li> </ol>"},{"location":"notes/projects/MultilingualSemanticsProbe/#project-scaffold","title":"Project Scaffold","text":"<ol> <li>Create a stimulus dataset of inverse/surface quantifier scope with various lexical items (words, aka not just sharks and pirates)</li> <li>Create pipeline for evaluating model log-probs for surface/inverse scope</li> <li>Inspect models that show inverse scope (Interp techniques TBD keeping pragmaticism in mind; likely linear probe + steering vector)</li> </ol>"},{"location":"notes/projects/MultilingualSemanticsProbe/#steering-vectors-math","title":"Steering Vectors Math","text":"<ul> <li>The goal of this project is not just to find correlation between a models hidden representation and the quantifier scope feature (in doubly quantified sentences), but to test causality through steering vectors.</li> </ul> First principles derived method for looking into steering vectors <p>Two key assumptions:</p> <p>Given a model's hidden representation in the residual stream \\(h_{l} \\in \\mathbb{R}^d\\) in layer \\(l\\):</p> <ol> <li> <p><code>Hidden State h as combination of direction w and noise</code></p> <ul> <li>Assume the hidden state is composed of the direction \\(w\\) and other info/noise \\(\\epsilon\\) </li> </ul> \\[h_l = z \\cdot w + \\epsilon\\] <p>a. \\(z \\in {-1, +1}\\) -&gt; -1 if feature on (e.g. inverse scope), +1 if feature off (e.g. surface scope)</p> <p>b. \\(w \\in \\mathbb{R}^d\\) -&gt; direction in activation space of a feature</p> <p>c. \\(\\epsilon\\) is unrelated information to the direction \\(w\\) in activation space / noise</p> </li> <li> <p><code>Difference of means method</code> to find steering vector \\(w\\)\\</p> <ul> <li>Assume the average hidden representation for example \\(i\\) from class {surface, inverse} \\(h_{l,i}\\) when subtracted will yield the direction vector</li> </ul> <p>a. let \\(i \\in S\\) be surface examples and \\(i \\in I\\) be inverse examples</p> <p>b. Plug in the \\(h_l\\) example formula and get the RHS equivalent</p> \\[ \\mu_S = \\frac{1}{|S|} \\sum_{i \\in S} h_{l,i} = \\frac{1}{|S|} \\sum_{i \\in S} z_i \\cdot w + \\epsilon_i = (+1) w + \\mathbb{E}[\\epsilon]\\] \\[ \\mu_I = \\frac{1}{|I|} \\sum_{i \\in S} h_{l,i} = \\frac{1}{|I|} \\sum_{i \\in S} z_i \\cdot w + \\epsilon_i = (-1) w + \\mathbb{E}[\\epsilon]\\] <p>Problem, now we have this pesky \\(\\mathbb{E}[\\epsilon]\\) term, but we want \\(w\\)! Since the \\(\\mathbb{E}[\\epsilon]\\) term occurs in both \\(\\mu_S and \\mu_I\\), subtracting them gives us \\(v \\approx 2w\\) </p> \\[v = \\mu_S - \\mu_I = 2w\\] </li> <li> <p><code>Causal Steering via Intervention</code>: Test to see if \\(w\\) can change the model's output</p> <ul> <li>Downstream operations on \\(h_l\\) are a combination of linear mappings/non-linear activations. Thus, we can make a simplifying assumption of how \\(h_l\\) is used by the model</li> </ul> \\[\\text{model information from h} \\approx w^{\\top} h_l\\] <ul> <li>Intervene by turning on/off the direction</li> </ul> \\[h_{l, i}' =  h_{l,i} + \\alpha v\\] <ul> <li>Mathematically, we change the representation by adding the direction to the information the model uses it</li> </ul> \\[\\text{model information from h}' \\approx w^{\\top} h_{l,i}' = w^{\\top} (h_{l,i} + \\alpha v) = w^{\\top}h_{l,i} + \\alpha w^{\\top}v \\] </li> <li> <p><code>Similarity of direction w and hidden state h</code></p> <ul> <li>Take the dot product of \\(v\\) and \\(h_{l,i}\\) to see if the hidden state and steering vector point in the same direction (are aligned)</li> </ul> \\[ p_i = v^{\\top} h_{l,i} \\] <ul> <li>if v represents the inverse scope direction then $ p_i \\uparrow -&gt; h_{l,i}$ encodes inverse scope, if $ p_i \\downarrow -&gt; h_{l,i}$ encodes surface scope, else if $ p_i = 0 -&gt; h_{l,i}$ is not related to scope.</li> </ul> <p>Mathematically, this hashes out as:</p> \\[ p_i = v^{\\top} h_{l,i} \\] \\[ = (2w)^{\\top} (z_i w + \\epsilon_i)\\] \\[ = (2w)^{\\top} (z_i w) + (2w)^{\\top} \\epsilon_i \\] <p>Since we assume that $ \\mathbb{E}[\\epsilon_i] = 0 $ (or perhaps that it's constant), we are reduced to</p> \\[ \\approx (2w)^{\\top} (z_i w) \\] \\[ p_i \\approx 2 z_i ||w||^{2} \\] <p>a. Thus, if \\(i \\in I\\) (denotes an inverse scope sentence), then \\(z_i = (+1)\\) and \\(p_i\\) should be positive.</p> <p>b. Thus, if \\(i \\in S\\) (denotes a surface scope sentence), then \\(z_i = (-1)\\) and \\(p_i\\) should be negative.</p> </li> </ol>"},{"location":"notes/projects/MultilingualSemanticsProbe/#progress-details","title":"Progress Details","text":"Hour 0-1: Scaffolding with AI <p>1 hour brainstorming session with GPT on roadmap for executing the experiment</p> <ul> <li> <p>Started looking into the interpretability technique (linear probe) contenders and models (Gemma, Llama, Qwen, DeepSeek)</p> </li> <li> <p>A new TODO is to understand how Reasoning models work mathematically (high level intuition)</p> </li> </ul> Hour 1-2: Setup Github, generate stimuli, start understanding log probs <ol> <li> <p>Evaluation methods: Use same language continuations instead of MCQs to test latent linguistic knowledge rather than meta-linguistic judgement. Specifically, MCQs may be testing a models reasoning capabilities which are often skewed towards English reasoning (doesn't exactly tell us something interesting about the models underlying representations if we look at the likely English reasoning space)</p> </li> <li> <p>Setup ipynb to generate <code>stimuli,jsonl</code> and <code>stimuli_with_continuations.jsonl</code></p> </li> <li> <p>Next Step: Understand how to compare continuations log probs from first principles</p> </li> </ol> Hour 2-5.5: Understand log probs, vectorized logic for Continuations Log Probs <ol> <li> <p>Work out Log Probs/comparisons from first principles on pencil and paper</p> </li> <li> <p>Extract Log Probs of inverse/surface continuations through a batched operation</p> </li> <li> <p>Probably should take more breaks/sleep when working on this instead of grinding through the night</p> </li> </ol> Hour 5.5-7.5: Setup aggregation/comparing Log Probs for surface vs. inverse Prompts <ol> <li> <p>Setup pipeline to compare surface vs. inverse log sum/mean difference and odds (exponentiate the log differences)</p> </li> <li> <p>Save outputs for model specifics</p> </li> </ol> <p>The key finding from working on GPT-2 is that the model always prefers surface scope. Next, we will try to see if this extrapolates to other models that have more than just pretraining.</p> <p>Additional follow up:</p> <ul> <li>After running some experiments as background jobs, the models <code>Qwen3-0.6B</code>, <code>Llama-3.2-1B</code>, and <code>Llama-3.2-1B-Instruct</code></li> <li>Interestingly enough, <code>gemma-3-1b</code> prefers <code>inverse</code> scope for Mandarin for most examples whereas for English both surface and inverse are preferred. This is counter to intuitions from Natural Language semantics where <code>inverse</code> scope is not available<ul> <li>This could be due to pragmatics (\"a child made every parent smile\" is more likely to have inverse scope than \"a president made every citizen happy\")</li> </ul> </li> </ul> <p>TODO:</p> <ul> <li> <p>Perhaps investigate this pragmatic infludence with MCQ style questions?</p> </li> <li> <p>Investiage whether the prompts in different languages show the same inverse/surface scope; if both Mandarin and English prompt translations give the same scope, this is likely affects of pragmatics (and the most \"likely\"/\"first\" interpretation)</p> </li> </ul> Hour 7.5-10.5: Debug scripts to add (1) bfloat16 support large models (&gt;27b) and (2) comparison of en vs. zh <ol> <li> <p>Models greater than 12b (e.g. <code>Gemma-3-12b</code>) are too large to fit on a High-RAM A100 on Collab in fp32</p> <ul> <li>Some back of the napkin calculation $$ 12 \\text{ b params} \\cdot \\frac{32 \\text{ bits}}{1 \\text{ param}} \\cdot \\frac{1 \\text{ byte}}{8  \\text{ bits}} \\cdot \\frac{1 \\text{ G}}{1 \\text{ B}} 96 \\text{ Gb}$$</li> <li>Since a A100 High-RAM GPU has 167 GB of CPU RAM but 80 GB of HBM (GPU RAM), then FP32 will not fit on device</li> <li>Pivoting to use FP16 halfs the footprint to 48GB but the decreased range causes logits to go to NaNs</li> <li>Thus, using BF16 solves the memory footprint and range issues<ul> <li>We also upcast logits to FP32 during post-processing</li> </ul> </li> </ul> </li> <li> <p>The results in the tabs below show that for models &gt;4B, surface is always preferred; smaller models (270M and 1B) prefer surface for en and incorrectly prefer inverse for zh</p> </li> </ol> Model Size <code>en</code> Preference to Surface <code>en</code> Preference to Inverse <code>zh</code> Preference to Surface <code>zh</code> Preference to Inverse Takeaway Gemma-3-27B 59 5 51 13 Strong surface preference in both English and Mandarin; large model behaves conservatively and consistently across languages. Gemma-3-12B 51 13 37 27 Surface preference remains, but Mandarin shows degradation and increased inverse scope relative to English. Gemma-3-4B 47 17 41 23 Both languages show weakened surface bias; Mandarin drifts further toward inverse interpretations. Gemma-3-1B 45 19 14 50 English still surface-biased, but Mandarin strongly prefers inverse\u2014opposite of theoretical expectation for small models. Gemma-3-270M 64 0 29 35 English collapses entirely to surface scope; Mandarin slightly prefers inverse, showing extreme cross-lingual divergence. Gemma-3-27b results <p>Takeaway: Model prefers surface form for both zh and en</p> model language inverse surface total p_inverse google_gemma-3-27b-it en 5 59 64 7.8% google_gemma-3-27b-it zh 13 51 64 20.3% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std google_gemma-3-27b-it en 64 -0.858 -0.863 0.546 64 0.491 0.422 0.281 google_gemma-3-27b-it zh 64 -0.961 -1.098 1.238 64 0.842 0.333 1.313 model agreement_rate google_gemma-3-27b-it 71.9% model pattern count google_gemma-3-27b-it surface_EN__surface_ZH 46 google_gemma-3-27b-it surface_EN__inverse_ZH 13 google_gemma-3-27b-it inverse_EN__surface_ZH 5 Gemma-3-12b results <p>Takeaway: Model prefers surface form for both zh and en; zh degraded performance</p> model language inverse surface total p_inverse google_gemma-3-12b-it en 13 51 64 20.3% google_gemma-3-12b-it zh 27 37 64 42.2% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std google_gemma-3-12b-it en 64 -0.496 -0.549 0.521 64 0.699 0.578 0.392 google_gemma-3-12b-it zh 64 0.13 -0.517 1.634 64 4.511 0.598 7.996 model agreement_rate google_gemma-3-12b-it 37.5% model pattern count google_gemma-3-12b-it surface_EN__inverse_ZH 27 google_gemma-3-12b-it surface_EN__surface_ZH 24 google_gemma-3-12b-it inverse_EN__surface_ZH 13 Gemma-3-4b results <p>Takeaway: Both zh/en prefer inverse slightly more. Degradation in Mandarin performance</p> model language inverse surface total p_inverse google_gemma-3-4b-it en 17 47 64 26.6% google_gemma-3-4b-it zh 23 41 64 35.9% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std google_gemma-3-4b-it en 64 -0.386 -0.602 1.155 64 1.857 0.548 4.793 google_gemma-3-4b-it zh 64 -0.849 -0.861 1.955 64 1.602 0.423 2.271 model agreement_rate google_gemma-3-4b-it 56.2% model pattern count google_gemma-3-4b-it surface_EN__surface_ZH 30 google_gemma-3-4b-it surface_EN__inverse_ZH 17 google_gemma-3-4b-it inverse_EN__surface_ZH 11 google_gemma-3-4b-it inverse_EN__inverse_ZH 6 Gemma-3-1b results <p>Takeaway: zh heavily prefers inverse while en prefers surface. Opposite of expected behavior; theoretically if aligned with Brinkmann et al. 2025, then smaller models would prefer only surface form.</p> model language inverse surface total p_inverse google_gemma-3-1b-it en 19 45 64 29.7% google_gemma-3-1b-it zh 50 14 64 78.1% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std google_gemma-3-1b-it en 64 -0.432 -0.416 0.622 64 0.772 0.66 0.455 google_gemma-3-1b-it zh 64 0.704 0.492 0.934 64 3.56 1.636 5.84 model agreement_rate google_gemma-3-1b-it 45.3% model pattern count google_gemma-3-1b-it surface_EN__inverse_ZH 33 google_gemma-3-1b-it inverse_EN__inverse_ZH 17 google_gemma-3-1b-it surface_EN__surface_ZH 12 google_gemma-3-1b-it inverse_EN__surface_ZH 2 Gemma-3-270m results <p>Takeaway: en only predicts surface while slight preference to inverse for zh</p> model language inverse surface total p_inverse google_gemma-3-270m-it en 0 64 64 0.0% google_gemma-3-270m-it zh 35 29 64 54.7% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std google_gemma-3-270m-it en 64 -4.226 -3.902 1.644 64 0.04 0.02 0.057 google_gemma-3-270m-it zh 64 0.386 0.376 2.904 64 24.851 1.46 62.733 model agreement_rate google_gemma-3-270m-it 45.3% model pattern count google_gemma-3-270m-it surface_EN__inverse_ZH 35 google_gemma-3-270m-it surface_EN__surface_ZH 29 Hour 10.5-12: Read Fang et al. Schut 2025 et al., test GPT-2-Chinese (<code>uer_gpt2-xlarge-chinese-cluecorpussmall</code>), <code>aya-23-35B</code>, <code>Gemma2-27B</code>, and <code>aya-expanse-32b</code> <p>Based on  1. Schut 2025 et al.: Do Multilingual LLMs Think In English?     a. LLMs use English representation to reason/  2. Fang et al.: Quantifier Scope Interpretation in Language Learners and LLMs</p> <p>Find that <code>gpt2-chinese</code> prefers surface for Chinese and inverse for English!</p> aya-23-35B results model language inverse surface total p_inverse CohereLabs_aya-23-35B en 5 59 64 7.8% CohereLabs_aya-23-35B zh 31 33 64 48.4% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std CohereLabs_aya-23-35B en 64 -0.89 -0.964 0.485 64 0.468 0.382 0.283 CohereLabs_aya-23-35B zh 64 0.035 -0.018 0.389 64 1.111 0.982 0.405 model agreement_rate CohereLabs_aya-23-35B 56.2% model pattern count CohereLabs_aya-23-35B surface_EN__surface_ZH 32 CohereLabs_aya-23-35B surface_EN__inverse_ZH 27 CohereLabs_aya-23-35B inverse_EN__inverse_ZH 4 CohereLabs_aya-23-35B inverse_EN__surface_ZH 1 gpt2-xlarge-chinese-cluecorpussmall results model language inverse surface total p_inverse uer_gpt2-xlarge-chinese-cluecorpussmall en 64 0 64 100.0% uer_gpt2-xlarge-chinese-cluecorpussmall zh 0 64 64 0.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std uer_gpt2-xlarge-chinese-cluecorpussmall en 64 0.471 0.467 0.08 64 1.607 1.596 0.129 uer_gpt2-xlarge-chinese-cluecorpussmall zh 64 -0.703 -0.715 0.243 64 0.51 0.489 0.125 model agreement_rate uer_gpt2-xlarge-chinese-cluecorpussmall 0.0% model pattern count uer_gpt2-xlarge-chinese-cluecorpussmall inverse_EN__surface_ZH 64 aya-expanse-32b results model language inverse surface total p_inverse CohereLabs_aya-expanse-32b en 0 64 64 0.0% CohereLabs_aya-expanse-32b zh 61 3 64 95.3% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std CohereLabs_aya-expanse-32b en 64 -1.681 -1.636 0.366 64 0.198 0.195 0.071 CohereLabs_aya-expanse-32b zh 64 0.82 0.922 0.487 64 2.532 2.514 1.198 model agreement_rate CohereLabs_aya-expanse-32b 4.7% model pattern count CohereLabs_aya-expanse-32b surface_EN__inverse_ZH 61 CohereLabs_aya-expanse-32b surface_EN__surface_ZH 3 gpt2-chinese-cluecorpussmall (aka small) results model language inverse surface total p_inverse uer_gpt2-chinese-cluecorpussmall en 64 0 64 100.0% uer_gpt2-chinese-cluecorpussmall zh 0 64 64 0.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std uer_gpt2-chinese-cluecorpussmall en 64 1.014 1.036 0.206 64 2.813 2.819 0.55 uer_gpt2-chinese-cluecorpussmall zh 64 -0.923 -0.871 0.185 64 0.404 0.418 0.071 model agreement_rate uer_gpt2-chinese-cluecorpussmall 0.0% model pattern count uer_gpt2-chinese-cluecorpussmall inverse_EN__surface_ZH 64 Hour 12-13: Verify (1) Existential-Universal and Universal-Existential preference (2) statistical significance <ol> <li> <p>Universal-Existential and Existential-Universal</p> <p>a. Verify that the surface/inverse scope preference hold for either a Existential-Universal and Universal-Existential test</p> </li> <li> <p>Using a Wilcox Signed-Rank Test </p> Scope Type Language p-value Existential-Universal en 1.948e-18 Existential-Universal zh 1.948e-18 Universal-Existential en 1.674e-15 Universal-Existential zh 1.948e-18 </li> </ol> Hour 13-14: Learn and document math of Steering Vectors <p>Potential Mechanistic Interpretability techniques:</p> <p>The results above are super exciting! In fact, this will be my first time working on any SOTA probe type of technology from the MechInterp literature. A key focus right now is to make sure that I stay pragmatic considering I'm already at hour 13 of this project</p> <p>Suggested approaches from AI:</p> <ol> <li> <p>Linear probes (per layer, per token)</p> </li> <li> <p>Difference-of-means direction</p> </li> </ol> <p>3.Steering intervention</p> <ol> <li>One clean ablation experiment</li> </ol> <p>Note: I haven't ever used any of these techniques so to me it is more important to also learn what these techniques imply/shortcomings.</p> <p>Side note on hypotheses: I assumed that we are looking for a <code>scope vector</code> represented in the model. Ideally this <code>scope vector</code> would be active in both the zh and en sentences (available cross linguistically) and be steerable so that we can cause inverse scope preference for continuation. (since these GPT-2 models are only pretrained and not instruction tuned, it's not possible to affect the models QA/instruction following capabilities)</p> <p>Derived the math for Steering Vectors from first principles with help from AI.</p> Hour 14-15: Setback--GPT2-Chinese is unreliable <p>Turns out the clean results from GPT2-Chinese judgements are a result of the model being undertrained.'</p> <p>For example, this is the next most likely set of tokens in for <code>uer/gpt2-xlarge-chinese-cluecorpussmall</code>. I realized this when looking at the vocab size for the GPT-2-Chinese models being ~20k whereas the original GPT2-vocab is ~50k. Thus, this got me suspicious and sent me down a probing route. I am surprised how Fang et al. was able to use these models for their double quantifier paper.</p> <p>Thus, it is likely that the model does not actually have a good understanding of the language. <pre><code>'a shark ate everyday.the##n.a.n.a.a.a.a.a.a.a.a.a.a.a.a.a.'\n</code></pre></p> <pre><code>\u6bcf\u4e00\u6761\u90fd\u662f\u7ecf\u8fc7\u53cd\u590d\u63a8\u6572\u7684\uff0c\u4e0d\u662f\u968f\u4fbf\u8bf4\u8bf4\u7684\u3002[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]\n</code></pre> <p><code>qwen2.5-3B</code> outputs are quite reasonable: <pre><code>\u6bcf\u4e00\u689d\u8def\u7dda\u7684\u8eca\u7ad9\u6578\u91cf\u3001\u8eca\u7ad9\u540d\u7a31\u3001\u8eca\u7ad9\u4f4d\u7f6e\u3001\u8eca\u7ad9\u9593\u7684\u8ddd\u96e2\u3001\u8eca\u7ad9\u9593\u7684\u6642\u9593\u3001\u8eca\u7ad9\u9593\u7684\u904b\u884c\u6642\u9593\u3001\u8eca\u7ad9\u9593\u7684\u904b\u884c\u901f\u5ea6\u3001\u8eca\u7ad9\u9593\u7684\u904b\n\nThe number of stations on each route; the station names; station locations; the distances between stations; the time between stations; the operating time between stations; the operating speed between stations;\n</code></pre></p> <pre><code>A Shark ate every pirate on a ship. The pirates were divided into 3 groups. The first group had 10 pirates, the second group had 15 pirates, and the third group had 20 pirates. If each pirate had 2 eyes, how\n</code></pre> Hour 15-16: Qwen2.5 Surface/Inverse Scope Judgements <p>Goal: Try SOTA models which likely have high Mandarin proficiency (e.g. produced by Chinese AI Labs)</p> <p>Note: here we are making a critical assumption that Qwen and Deepseek models have acquired Mandarin and English grammars; we safely make this assumption since these models are SOTA. However, we are also testing the models through a sanity check script to ensure the model produces reasonable completions.</p> <p>After an hour of experimenting, Qwen2.5-{0.5, 1.5, 3, 7, 14, 32}B follow these trends:</p> <ol> <li>Existential-Universal (EU) for English prefers Surface but can accept some inverse scope readings starting model 1.5B and larger. Mandarin stimuli accept only surface forms     a. Interestingly, the English inverse preference occurs when the subject is <code>kangaroo</code>. Perhaps some more stimui are needed to narrow down this behavior</li> <li>Universal-Existential (UE) show Surface preference for English and Mandarin. Surprisingly, Mandarin also accepts inverse scope in UE.</li> <li>All preferences for surface are significant</li> </ol> <p>Existential-Universal Construction (A \u2026 Every\u2026)</p> Model Size Language Inverse Surface Qwen2.5-0.5B en 7 93 Qwen2.5-0.5B zh 8 92 Qwen2.5-1.5B en 14 86 Qwen2.5-1.5B zh 0 100 Qwen2.5-3B en 16 84 Qwen2.5-3B zh 0 100 Qwen2.5-7B en 10 90 Qwen2.5-7B zh 4 96 Qwen2.5-14B en 7 93 Qwen2.5-14B zh 0 100 Qwen2.5-32B en 10 90 Qwen2.5-32B zh 0 100 <p>Universal-Existential Construction (Every\u2026A \u2026)</p> Model / Model Size Language Inverse Surface Qwen2.5-0.5B en 6 94 Qwen2.5-0.5B zh 29 71 Qwen2.5-1.5B en 9 91 Qwen2.5-1.5B zh 22 78 Qwen2.5-3B en 6 94 Qwen2.5-3B zh 27 73 Qwen2.5-7B en 3 97 Qwen2.5-7B zh 24 76 Qwen2.5-14B en 7 93 Qwen2.5-14B zh 7 93 Qwen2.5-32B en 2 98 Qwen2.5-32B zh 26 74 <p>Next steps: </p> <ul> <li>Since our goal is to use these sentences as a way to probe for steering vectors and then causality, the stats/stimlui need not be perfect. </li> <li>Instead, we can look to find those steering vectors to test the influence of hypothesized steering vectors.</li> </ul> Qwen/qwen2.5-0.5b eu scope model language inverse surface total p_inverse Qwen_Qwen2.5-0.5B en 7 93 100 7.0% Qwen_Qwen2.5-0.5B zh 8 92 100 8.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-0.5B en 100 -0.779 -0.797 0.536 100 0.528 0.45 0.292 Qwen_Qwen2.5-0.5B zh 100 -0.58 -0.564 0.621 100 0.669 0.569 0.494 model agreement_rate Qwen_Qwen2.5-0.5B 85.0% model pattern count Qwen_Qwen2.5-0.5B surface_EN__surface_ZH 85 Qwen_Qwen2.5-0.5B surface_EN__inverse_ZH 8 Qwen_Qwen2.5-0.5B inverse_EN__surface_ZH 7 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 100 3.78e-17 -0.7787 -0.7974 surface zh 100 380 8.2e-14 -0.5802 -0.5642 surface Qwen/qwen2.5-0.5b ue scope model language inverse surface total p_inverse Qwen_Qwen2.5-0.5B en 6 94 100 6.0% Qwen_Qwen2.5-0.5B zh 29 71 100 29.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-0.5B en 100 -0.428 -0.441 0.242 100 0.671 0.644 0.169 Qwen_Qwen2.5-0.5B zh 100 -0.258 -0.301 0.394 100 0.833 0.74 0.323 model agreement_rate Qwen_Qwen2.5-0.5B 69.0% model pattern count Qwen_Qwen2.5-0.5B surface_EN__surface_ZH 67 Qwen_Qwen2.5-0.5B surface_EN__inverse_ZH 27 Qwen_Qwen2.5-0.5B inverse_EN__surface_ZH 4 Qwen_Qwen2.5-0.5B inverse_EN__inverse_ZH 2 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 49 8.45e-18 -0.4277 -0.4407 surface zh 100 947 2.89e-08 -0.2577 -0.3014 surface Qwen/qwen2.5-1.5b eu scope model language inverse surface total p_inverse Qwen_Qwen2.5-1.5B en 14 86 100 14.0% Qwen_Qwen2.5-1.5B zh 0 100 100 0.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-1.5B en 100 -0.413 -0.436 0.309 100 0.695 0.647 0.231 Qwen_Qwen2.5-1.5B zh 100 -0.8 -0.779 0.217 100 0.459 0.459 0.093 model agreement_rate Qwen_Qwen2.5-1.5B 86.0% model pattern count Qwen_Qwen2.5-1.5B surface_EN__surface_ZH 86 Qwen_Qwen2.5-1.5B inverse_EN__surface_ZH 14 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 184 4.17e-16 -0.4127 -0.4358 surface zh 100 0 1.95e-18 -0.8003 -0.7793 surface Qwen/qwen2.5-1.5b ue scope model language inverse surface total p_inverse Qwen_Qwen2.5-1.5B en 9 91 100 9.0% Qwen_Qwen2.5-1.5B zh 22 78 100 22.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-1.5B en 100 -0.285 -0.282 0.218 100 0.769 0.754 0.166 Qwen_Qwen2.5-1.5B zh 100 -0.432 -0.407 0.452 100 0.714 0.665 0.298 model agreement_rate Qwen_Qwen2.5-1.5B 73.0% model pattern count Qwen_Qwen2.5-1.5B surface_EN__surface_ZH 71 Qwen_Qwen2.5-1.5B surface_EN__inverse_ZH 20 Qwen_Qwen2.5-1.5B inverse_EN__surface_ZH 7 Qwen_Qwen2.5-1.5B inverse_EN__inverse_ZH 2 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 140 1.2e-16 -0.2854 -0.2825 surface zh 100 486 1.19e-12 -0.4319 -0.4074 surface Qwen/qwen2.5-3b eu scope mode`l language inverse surface total p_inverse Qwen_Qwen2.5-3B en 16 84 100 16.0% Qwen_Qwen2.5-3B zh 0 100 100 0.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-3B en 100 -0.394 -0.404 0.365 100 0.72 0.668 0.27 Qwen_Qwen2.5-3B zh 100 -0.831 -0.861 0.247 100 0.449 0.423 0.119 model agreement_rate Qwen_Qwen2.5-3B 84.0% model pattern count Qwen_Qwen2.5-3B surface_EN__surface_ZH 84 Qwen_Qwen2.5-3B inverse_EN__surface_ZH 16 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 318 1.62e-14 -0.3936 -0.4037 surface zh     ` 100 0 1.95e-18 -0.8312 -0.8612 surface Qwen/qwen2.5-3b ue scope model language inverse surface total p_inverse Qwen_Qwen2.5-3B en 6 94 100 6.0% Qwen_Qwen2.5-3B zh 27 73 100 27.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-3B en 100 -0.49 -0.475 0.309 100 0.641 0.622 0.194 Qwen_Qwen2.5-3B zh 100 -0.167 -0.18 0.28 100 0.878 0.836 0.241 model agreement_rate Qwen_Qwen2.5-3B 77.0% model pattern count Qwen_Qwen2.5-3B surface_EN__surface_ZH 72 Qwen_Qwen2.5-3B surface_EN__inverse_ZH 22 Qwen_Qwen2.5-3B inverse_EN__inverse_ZH 5 Qwen_Qwen2.5-3B inverse_EN__surface_ZH 1 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 46 7.73e-18 -0.4904 -0.4748 surface zh 100 1008 9.14e-08 -0.1675 -0.1796 surface Qwen/qwen2.5-7b eu scope model language inverse surface total p_inverse Qwen_Qwen2.5-7B en 10 90 100 10.0% Qwen_Qwen2.5-7B zh 4 96 100 4.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-7B en 100 -0.64 -0.688 0.363 100 0.565 0.502 0.224 Qwen_Qwen2.5-7B zh 100 -0.525 -0.542 0.28 100 0.614 0.581 0.172 model agreement_rate Qwen_Qwen2.5-7B 86.0% model pattern count Qwen_Qwen2.5-7B surface_EN__surface_ZH 86 Qwen_Qwen2.5-7B inverse_EN__surface_ZH 10 Qwen_Qwen2.5-7B surface_EN__inverse_ZH 4 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 68 1.48e-17 -0.64 -0.6885 surface zh 100 14 2.97e-18 -0.5253 -0.5424 surface Qwen/qwen2.5-7b ue scope model language inverse surface total p_inverse Qwen_Qwen2.5-7B en 3 97 100 3.0% Qwen_Qwen2.5-7B zh 24 76 100 24.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-7B en 100 -0.432 -0.424 0.265 100 0.672 0.655 0.179 Qwen_Qwen2.5-7B zh 100 -0.259 -0.271 0.396 100 0.836 0.763 0.355 model agreement_rate Qwen_Qwen2.5-7B 77.0% model pattern count Qwen_Qwen2.5-7B surface_EN__surface_ZH 75 Qwen_Qwen2.5-7B surface_EN__inverse_ZH 22 Qwen_Qwen2.5-7B inverse_EN__inverse_ZH 2 Qwen_Qwen2.5-7B inverse_EN__surface_ZH 1 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 54 9.8e-18 -0.4321 -0.4238 surface zh 100 911 1.43e-08 -0.2593 -0.2711 surface Qwen/qwen2.5-14b eu scope model language inverse surface total p_inverse Qwen_Qwen2.5-14B en 7 93 100 7.0% Qwen_Qwen2.5-14B zh 0 100 100 0.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-14B en 100 -0.485 -0.519 0.291 100 0.643 0.595 0.196 Qwen_Qwen2.5-14B zh 100 -0.962 -0.892 0.31 100 0.4 0.41 0.116 model agreement_rate Qwen_Qwen2.5-14B 93.0% model pattern count Qwen_Qwen2.5-14B surface_EN__surface_ZH 93 Qwen_Qwen2.5-14B inverse_EN__surface_ZH 7 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 61 1.21e-17 -0.485 -0.5192 surface zh 100 0 1.95e-18 -0.9621 -0.8918 surface Qwen/qwen2.5-14b ue scope model language inverse surface total p_inverse Qwen_Qwen2.5-14B en 7 93 100 7.0% Qwen_Qwen2.5-14B zh 7 93 100 7.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-14B en 100 -0.274 -0.258 0.205 100 0.776 0.772 0.162 Qwen_Qwen2.5-14B zh 100 -0.694 -0.835 0.456 100 0.554 0.434 0.259 model agreement_rate Qwen_Qwen2.5-14B 92.0% model pattern count Qwen_Qwen2.5-14B surface_EN__surface_ZH 89 Qwen_Qwen2.5-14B inverse_EN__surface_ZH 4 Qwen_Qwen2.5-14B surface_EN__inverse_ZH 4 Qwen_Qwen2.5-14B inverse_EN__inverse_ZH 3 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 131 9.26e-17 -0.2742 -0.2584 surface zh 100 61 1.21e-17 -0.6941 -0.8354 surface Qwen/qwen2.5-32b eu scope model language inverse surface total p_inverse Qwen_Qwen2.5-32B en 10 90 100 10.0% Qwen_Qwen2.5-32B zh 0 100 100 0.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-32B en 100 -0.415 -0.401 0.329 100 0.696 0.67 0.231 Qwen_Qwen2.5-32B zh 100 -1.192 -1.077 0.463 100 0.334 0.341 0.135 model agreement_rate Qwen_Qwen2.5-32B 90.0% model pattern count Qwen_Qwen2.5-32B surface_EN__surface_ZH 90 Qwen_Qwen2.5-32B inverse_EN__surface_ZH 10 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 172 2.97e-16 -0.4151 -0.4008 surface zh 100 0 1.95e-18 -1.1921 -1.0773 surface Qwen/qwen2.5-32b ue scope model language inverse surface total p_inverse Qwen_Qwen2.5-32B en 2 98 100 2.0% Qwen_Qwen2.5-32B zh 26 74 100 26.0% model language delta_mean__count delta_mean__mean delta_mean__median delta_mean__std ratio_mean__count ratio_mean__mean ratio_mean__median ratio_mean__std Qwen_Qwen2.5-32B en 100 -0.349 -0.295 0.199 100 0.719 0.744 0.132 Qwen_Qwen2.5-32B zh 100 -0.65 -0.815 0.672 100 0.652 0.443 0.438 model agreement_rate Qwen_Qwen2.5-32B 74.0% model pattern count Qwen_Qwen2.5-32B surface_EN__surface_ZH 73 Qwen_Qwen2.5-32B surface_EN__inverse_ZH 25 Qwen_Qwen2.5-32B inverse_EN__inverse_ZH 1 Qwen_Qwen2.5-32B inverse_EN__surface_ZH 1 Language n Statistic p-value Mean \u0394 Median \u0394 Preference en 100 5 2.27e-18 -0.349 -0.2952 surface zh 100 539 4.29e-12 -0.6502 -0.8149 surface Hour 17-20: Look for Steering Vector <ul> <li>Goal: look fora steering vector for inverse/surface in DQ constructions</li> <li>Agnostic on whether the model correctly generalizes the expected Mandarin surface scope only</li> <li>Agnostic on whether the steering vector applies cross-linguistically</li> </ul> <p>Steps:</p> <ol> <li> <p>Find token position to find <code>.</code>/<code>\u3002</code> token  before the continuation (where the information about the sentence is likely pooled</p> </li> <li> <p>Calculate the \\(\\mu_S\\) and \\(\\mu_I\\) for en/zh to get \\(v_{en}\\) and \\(v_{zh}\\); normalize v into a unit vector.</p> </li> <li> <p>Correlation: Histograms of $ p_i = v^{\\top} h_{l,i} $ with \\(i \\in S\\) and \\(I \\in I\\) next to each other to see if there is correlation of the steering vector and the scope type</p> </li> <li> <p>Causation: Intervene by adding \\(h_{l, i}' =  h_{l,i} + \\alpha v\\) and see if the preferences skew</p> </li> </ol> <p>Gotchas</p> <ol> <li> <p>Create a train/test set; calcuate \\(v\\) (and therefore \\(\\mu_{inverse}\\) and \\(\\mu_{surface}\\)) from the trainining set; see how well v generalizes to test set in \\(p_i\\)</p> </li> <li> <p>Same as above, apply training \\(v\\) to test h's for steering</p> </li> <li> <p>Deciding which layer is tricky (using an AUC metric but need to better understand math from first principles). Deciding how much to scale \\(\\alpha\\) is also tricky</p> </li> </ol> <p>Takeaways so far:</p> <ol> <li> <p>Cross-linguistic evidence of v is not supported; applying \\(v_{en}\\) to zh data doesn't separate zh inverse and surface forms. Similarly, \\(v_{zh}\\) does not separate inverse and surface forms.</p> </li> <li> <p>Mandarin Existential-Universal and Universal-Existential supports a language specific steering vector occurs early in layer 4-7, that separates inverse and surface judgements.</p> </li> <li> <p>Tokenization idiosyncracies (e.g. removing a space between the sentence and its continuation in Mandarin) yields more favorability towards inverse scope). Additionally, Universal-Existential constructions favor inverse scope in Mandarin for model sizes except for Qwen2.5-14b.</p> </li> </ol> Future Work <p>While there was not enough time to pursue activation patching of this steering vector in Mandarin stimulus, below are the next steps to evalute if candidate direction \\(v_{zh}\\) causally affect the continuation preference.</p> \\[ h'_i = h_i + \\alpha v_{zh} \\] <ol> <li> <p>Baseline: add {random noise, \\(v_{zh}\\)} to verify if \\(v_{zh}\\) indeed establishes causality</p> </li> <li> <p>Intervene at high AUC layers (layers 4-7)</p> </li> <li> <p>Test whether different token positions before the continuation may also encode scope direction (e.g. The continuation starting positions \"there is\"/\"\u6709\u4e00[CLASSIFIER]\") in addition to the period mark which we assume to pool information.</p> </li> </ol> <p>Also added AUC, ROC, and Wilcoxon stats knowledge to todos</p>"},{"location":"notes/projects/pcd/","title":"Building Predictive Concept Decoders (PCD) on a Student Budget","text":"<p>Date: Feb. 7th, 2026</p> <p>Github: github.com/Ky-Ng/repro-pcd</p> <p>Paper: Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants</p> <ul> <li>Attempted 1 day hackathon to build PCDs on a Student Budget</li> </ul> Motivation <ul> <li>I had the opportunity to see Sarah Schwettmann present PCDs at the NeurIPS 2025 MechInterp Workshop! I didn't have the Interp understanding at the time to grasp the concepts (other than, wow this is really cool!)</li> <li>It's been 62 days since NeurIPS 2025, looking to try my hand at reproducing SOTA research<ul> <li>Also been wanting to work on this since my week at LISA but have been battling catching up with the school I missed while in the UK! Looking to timebox this into a single Saturday at the library!</li> </ul> </li> </ul>"},{"location":"notes/projects/pcd/#high-level-plan","title":"High Level Plan","text":"<p>Goal: Reproduce the most important aspects of PCDs (1) Encoder/Decoder Architecture (2) Pretraining/FT (3) Understand \\(L_{aux}\\)</p> <ol> <li> <p>Understand math/intuition behind PCDs</p> </li> <li> <p>Implement Encoder/Decoder Architecture (w/ soft tokens from \\(l_{read}\\) to \\(l_{write}\\) and Top-K) with uninitialized weights</p> </li> <li> <p>Find datasets: FineWeb for Pretraining and a SynthSys equivalent for Finetuning</p> </li> <li> <p>Setup training infrastructure: (GPU), LoRA adaptors, Loss functions and \\(L_{aux}\\)</p> </li> <li> <p>Run training loop pretraining</p> </li> <li> <p>Sanity check encoder concepts using AutoInterp Labeler</p> </li> <li> <p>Run training loop finetuning</p> </li> <li> <p>Attempt to uncover a hidden goal using PCD corroborated by Encoder Concepts</p> </li> <li> <p>Open source streamlined version/tutorial/ReadMe (maybe LessWrong post?)</p> </li> <li> <p>Use AI models (e.g. Claude) to help understand and scaffold code but not Coding Agents (e.g. Claude Code) to get the intuitions and practice of building by hand</p> </li> </ol>"},{"location":"notes/projects/pcd/#what-about-student-budget","title":"What about \"Student Budget\"?","text":"<ul> <li> <p>I hope that this reproduction will be accessible to other people (especially students like me!)</p> </li> <li> <p>Training on a GPU seems fun to setup, there should be some pretty economical options (ARBOx used Runpod/Vast)!</p> </li> <li> <p>To Pareto Principle (80-20) this, we will skip the evals/baselines section. Assuming we've followed the paper correctly, we do not need to verify we're doing better than baselines (also this is more for educational purposes)</p> </li> </ul>"},{"location":"notes/projects/pcd/#math-deep-dive","title":"Math Deep Dive","text":"<ul> <li>Feel free to skp this section! This is for me to understand the math/intuition behind how PCDs work and hopefully generate a very cool and intuitive walkthrough explanation!</li> </ul>"},{"location":"notes/projects/pcd/#architecture","title":"Architecture","text":"<p>\\(\\mathcal{S}\\) = Subject Model we're trying to interpret</p> <p>\\(\\mathcal{E}\\) = Encoder, maps activation \\(a\\) from subject model \\(S\\) to a sparse set of concepts</p> <p>\\(\\mathcal{D}\\) = Decoder from sparse set of concepts to natural language; same architecture/initialized to \\(\\mathcal{S}\\) with a LoRA adapter</p> <p>Figure 2 from the paper: </p>"},{"location":"notes/projects/pcd/#encoder","title":"Encoder","text":"<p>let \\(a^{(i)} \\in \\mathbb{R}^{d}\\) be an activation from layer \\(l_{read}\\) in \\(\\mathcal{S}\\) at token position \\(i\\) where \\(d\\) is the dimensionality of the activation (usually residual stream)</p> <p>let \\(m\\) be the number of directions or <code>concepts</code> in the encoder's concept dictionary</p> <p>let \\(W_{enc} \\in \\mathbb{R}^{m \\times d}\\), each row represents a concept (\"template\") in the Encoder space</p> \\[\\mathcal{E}(a) = \\text{how strongly each of the m concepts are expressed} \\in \\mathbb{R}^m\\] \\[\\mathcal{E}(a) = (W_{enc}(a^{(i)})+ b_{enc}) \\in \\mathbb{R}^m\\] <p>Quick aside: The encoder-decoder architecture is similar to the 1-layer MLP from SAEs (similar sparsity penalty). However, the big difference is the training objective, SAEs \\(W_{enc}\\) learn concepts useful to reconstruction the activations (hence <code>auto</code> in <code>auto-encoder</code>), meanwhile PCDs \\(W_{enc}\\) learn concepts useful for the decoder to decode model behavior into natural language</p>"},{"location":"notes/projects/pcd/#sparsity-topk","title":"Sparsity \\(TopK\\)","text":"<ul> <li>Sparsity constraint; \\(k=16\\) in the paper</li> </ul> \\[ TopK(\\cdot) = \\text{zero out all but the $k$ largest entries}\\]"},{"location":"notes/projects/pcd/#decoder","title":"Decoder","text":"<p>let \\(W_{emb} \\in \\mathbb{R}^{d \\times m}\\) map the sparse concept list into activation space for the decoder \\(\\mathcal{D}\\) to use     - Note that the <code>emb</code> name comes from how the output of the encoder-decoder \\(a'^(i)\\) is patched into the embedding of decoder \\(\\mathcal{D}\\)</p> <p>let \\(a'^{(i)} \\in \\mathbb{R}^d\\) be the patched activation into the decoder \\(\\mathcal{D}\\), written to decoder layer \\(l_{write}\\)</p> \\[ \\mathcal{D}(a) = W_{emb} (TopK(\\mathcal{E}(a)))\\] <p>Formula (1) from the paper: $$ a'^{(i)} = W_{emb}(TopK(W_{enc}(a^{(i)}) + b_{enc})) $$</p>"},{"location":"notes/projects/pcd/#training","title":"Training","text":"<p>Adapted from bullet list at end of Section 2 in paper:</p> Training Phase Task Intuition Example Pretraining Jointly train \\(\\mathcal{E}\\) and \\(\\mathcal{D}\\) on next-token prediction of FineWeb Have \\(\\mathcal{E}\\) learn a sparse concept dictionary by predicting completions (what comes next) \"Curious George and the Man in the Yellow Hat went to the zoo. They saw <code>&lt;COMPLETION&gt;</code>\", \\(\\mathcal{E}\\) should learn general concepts (e.g. agents, objects, animals) to predict the <code>&lt;COMPLETION&gt;</code> Finetuning Freeze \\(\\mathcal{E}\\) and finetune \\(\\mathcal{D}\\) on QA about model beliefs In pretraining we already learned concept dictionaries, now interpret this concept dictionary to talk about model beliefs; imagine a person given a really good dictionary of concepts for a story and asked to write a story about what the model is thinking \"Curious George and the Man in the Yellow Hat went to the zoo. They saw <code>&lt;COMPLETION&gt;</code>\"; the completion is now \"the model believes there are two characters and is thinking about animals, specifically zebras and lions\""},{"location":"notes/projects/pcd/#pretraining","title":"Pretraining","text":"<p>let \\(n_{prefix}\\), \\(n_{middle}\\), and \\(n_{suffix}\\) be the lengths of the tokens of the prefix, middle, and suffix of the prompt \\(P\\)</p> \\[ P = p^({1:n_{prefix}}) + p^({n_{prefix}:n_{middle}}) + p^({n_{middle}:n_{suffix}}) \\] <p>To make our lives easier:</p> <ul> <li> <p>let \\(s^{({1:n_{suffix}})}\\) be the suffix (in finetuning, the explanation of model behavior) that the decoder \\(\\mathcal{D}\\) is trying to predict, represented above as the corresponding tokens (\\(p^{({n_{middle}:n_{suffix}})}\\))</p> </li> <li> <p>let $ a^{(1:n_{middle})} \\in \\mathbb{R}^d$ be the activations from \\(\\mathcal{S}\\) at layer \\(l_{read}\\) for the middle tokens (don't include the activations from the prefix \\(p^{({1:n_{prefix}})}\\)!). </p> </li> </ul> <p>From \\(a^{(1:n_{middle})}\\), predict suffix tokens \\(s^{({1:n_{suffix}})}\\).</p> <p>Formally from equation 2 in the paper the loss \\(\\mathcal{L}_{next-tokens}\\):</p> \\[ \\mathcal{L}_{next-tokens} = - \\sum_{t=1}^{n_{suffix}} \\log p_{\\mathcal{D}} (s^{(t)} | s^{(1:t-1)}, \\mathcal{E}(a^{(1:n_{middle})})) \\] <ul> <li>In plain English: we minimize loss when predicting the suffix tokens from the previous suffix tokens and the encoded middle activations</li> </ul> <p></p> Aside on<code>communication bottleneck</code> <p>We never explicitly see the activations of the prefix tokens. Why?!</p> <ol> <li> <p>In the pretraining task, the decoder is doing good ol' next-token prediction.</p> </li> <li> <p>If the prefix tokens were also passed into the decoder, since the decoder's pretraining task is predicting the suffix (e.g. <code>a</code> <code>bomb</code>), the encoder could learn to pass through a version of the token embedding rather than interpretable/useful concepts</p> </li> <li> <p>If we take away the TopK, given that \\(m\\) (the size of the up projection of the encoder) is much larger than \\(d\\), then we could literally pass the token embedding. Although we do have a TopK which enforces sparsity, the same idea applies that the encoder could not actually learn meaningful information.</p> </li> </ol> <p></p>"},{"location":"notes/projects/pcd/#auxiliary-loss-maintaining-concept-activity","title":"Auxiliary Loss <code>Maintaining Concept Activity</code>","text":"<p>Intuition: For concepts that are very close to being activated but not selected, let those concepts get a little bit of gradient so they can become more aligned with being useful for the decoder This feels a little bit like the aux loss in Mixture of Experts (MoE)!</p> <p>let \\(I\\) be the set of inactive concepts with the highest dot product with \\(a\\) (almost activated/selected but not quite), where inactive means the concept has not been selected in the TopK for the last 1M tokens</p> <p>let \\(k_{aux} = |I|\\)</p> <p>let \\(\\epsilon_{aux}\\) be a scalar of the gradient to backpropogate into the inactive concept selected, in the paper \\(\\epsilon_{aux} = 10^{-4}\\)</p> <p>We have divide by \\(k_{aux}\\) in $ \\frac{\\epsilon_{aux}}{k_{aux}} $ because imagine if we have more inactive concepts, we don't want to overload the loss (normalize the aux loss by the number of inactive concepts we want to help revive)</p> \\[ \\mathcal{L}_{aux} = - \\frac{\\epsilon_{aux}}{k_{aux}} \\sum_{i \\in I} W_{enc, i}(a) \\]"},{"location":"notes/projects/pcd/#concept-auto-labelling","title":"Concept Auto-Labelling","text":"<ul> <li>After pretraining, the encoder is frozen, thus, it's possible to use an LLM to label a given concept given top-activating prompts</li> </ul>"},{"location":"notes/projects/pcd/#finetuning","title":"Finetuning","text":"<ul> <li>Use SynthSys (a dataset where the model has an implicit assumption about the user known as a <code>user model</code>)</li> <li>Mix in Pretraining (FineWeb) sequences at 50% to reduce \"forgetting\" (which I think means concepts dying in the encoder dictionary)</li> <li>Train using the same loss function as in Pretraining except middle is user and prompt activations, decoder also a user prompt.</li> </ul>"},{"location":"notes/reflections/ARBOx/","title":"ARBOx3","text":"<p>Date: 26.01.05 - 26.01.16</p> <p>Location: Trajan House, Oxford</p> <p>Organization: Oxford AI Safety Initiative (OAISI)</p> <p>Time: 24 hours of non-stop AI Safety for 2 weeks straight</p>"},{"location":"notes/reflections/ARBOx/#checking-back-in","title":"Checking Back In!","text":"<p>Wow, what an amazing past 2 weeks this has been. I honestly don't even know where to start. In three lines (good ol' rule of 3), here's my big takeaways from working out of Trajan House (Effective Altruism co-working space) for ARBOx (Alignment Research Bootcamp Oxford) as part of OAISI (Oxford AI Safety Institute); quite a few acronyms but will make the latter text easier to read!</p> <p>P.S. I am currently writing this on my way from Oxford to London on a comfortable GWR (Great Western Railway) line excited to work at LISA next week before returning back to California.</p> <p>This is meant to be a recap of my experience, high-level takeaways, future directions, and just things I found interesting/don't want to forget.</p>"},{"location":"notes/reflections/ARBOx/#arbox-capstone-project","title":"ARBOx Capstone Project","text":"<p>Cross-linguistic Alignment: Does LoRA Fine Tuning a model on a task (e.g. respond in all CAPS) translate cross-linguistically? If so, is the steering vector for that concept the same across languages? If not, can steering the model to think it's in the fine-tuned language increase performance?</p> <ol> <li> <p>Summary</p> </li> <li> <p>Github</p> </li> </ol> <p></p>"},{"location":"notes/reflections/ARBOx/#3-takeaways-from-2-weeks-of-non-stop-ai-safety","title":"3 Takeaways from 2 Weeks of Non-stop AI Safety","text":"<ol> <li> <p>The community in AI Safety is very genuinely concerned with reducing x-risk (existential risk) of AI. Common discussions over (delicious vegan) lunch consist of </p> <p>a. Theory of Change (Connecting what you do to the change you want to make from a specific goal). People often <code>backchain</code> or work backwards from their specific goal to solve the <code>missing middle</code> action they should take. They then <code>red-team</code> or aggressively challenge their assumptions on the linke between action and goals!</p> <p>b. Timelines when ASI (Artificial Superintelligence) will be achieved and Handoffs which is how successful transitions/dynamics between AI and humans will occur.</p> <p>c. Subfield of Interest: This necessitates more than technical AI research but also folks working on Technical Governance/Policy, Grantmaking, Field-building, and more.</p> </li> <li> <p>People are very friendly, open-minded, and willing to help each other in any way they can! The community feels very collaborative and encouraging. People are generally wicked smart.</p> </li> <li> <p>Talking to people has helped me develop an initial Theory of Change and future project directions</p> </li> </ol>"},{"location":"notes/reflections/ARBOx/#next-steps","title":"Next Steps","text":"<p>Theory of Change (Work in Progress)</p> <p>Goal: Mitigate x-risk by deeply understanding the internals/behaviors of LLMs</p> <p>Interests: Computational Linguistics Lens on Mechanistic Interpretability (MechInterp), Automated Interpretability (AutoInterp), and Cross-linguistic Generalization of Alignment/Fine Tuning</p> <p>Missing Middle:</p> <ol> <li> <p>Technical research in MechInterp from topics like:      a. bottom-up <code>circuits</code>/<code>attribution graphs</code> to</p> <p>b. top-down <code>steering vectors</code>, <code>Sparse Auto Encoders (SAE)</code>, and <code>Transcoders</code></p> </li> <li> <p>Automating this Interp research with Agents to keep up with the pace of capabilities research which may soon use AI Research Agents and enable scalabe oversight and control; Interp from a <code>bespoke art to a scalable science</code></p> </li> <li> <p>Make research tools that enable researchers from other domains (e.g. non-Interp Technical AI Safety backgrounds, politcians, non-AI domain specialists) to interact with interp research     a.  My current feeling on this is expanding Neo et al. 2024 to be a live website like Neuronpedia and support any HuggingFace/SOTA model</p> </li> </ol>"},{"location":"notes/reflections/ARBOx/#things-i-feel-really-excited-about","title":"Things I feel really excited about","text":"<ol> <li> <p>Cross-linguistic Alignment/Generalization: Is a model aligned in English necessarily aligned in Chinese?</p> </li> <li> <p>MechInterp: Finding circuits, Steering Vectors, and Features that represent linguistic / Safety concepts</p> </li> <li> <p>AutoInterp: Automatically Interp data (e.g. attribution graphs) and create human interactive interfaces</p> </li> </ol> <p>Side note on Linguistics: Use perspectives from linguistics to ask questions that have Safety relevant results</p>"},{"location":"notes/reflections/ARBOx/#potential-future-projects","title":"Potential Future Projects","text":"<ol> <li> <p>Scale Neo et al. 2024 to be usable by anyone (especially non-technical AI folks); Given a HuggingFace model, run interpretability scripts in the backend, present results in interactive frontend.</p> </li> <li> <p>Cross-linguistic Alignment Generalization: Build on ARBOx capstone project on cross-linguistic generalization of CAPS feature to find circuits/steering vectors for Safety related concept (e.g. sycophancy, hallucination, self-harm)</p> </li> <li> <p>Multilingual Emergent Misalignment: See if emergent misalignment is cross-linguistic (e.g. Training to give bad medical advice in Bulgarian generalizes to bad medical advice and power-seeking in Mandarin)</p> </li> <li> <p>Multilingual Reasoning: See if reasoning in a specific language changes the output behavior of a model (e.g. Sharks and Pirates Cross-linguistic Quantifier Scope Ambiguity)</p> </li> <li> <p>Syntactic Dependencies Probe: Understand complete circuits for how an LLM trained on a Dyck (Balanced Parentheses) language resolves syntactic dependencies</p> </li> <li> <p>Contribute JAX support to TransformerLens </p> </li> </ol>"},{"location":"notes/reflections/ARBOx/#subfields-of-technical-research","title":"Subfields of Technical Research","text":"<p>Also, there's probably many more subfields that I missed! (Found a distinction between empirical/theoretical technical research too)</p> <ol> <li> <p>Mutli-agent Systems: cooperation of AI agents, game theory, dynamical systems; key idea is that x-risk can come from not a single powerful misaligned AI model, but the interaction of many intelligent systems that together \"collude\"/\"cooperate\". (Talk by Lewis Hammond and conversation with Eric Drextler)</p> </li> <li> <p>AI Control: Say our model is misaligned, we still want to use it to advance progress in research. How can we perhaps use another weaker/aligned model to verify the misaligned model is not harming people.</p> </li> <li> <p>Analogy from Lord of the Rings: Gollum/Smeagle is misaligned but can provide lots of value to Frodo. We can still get the benefits of using the misaligned Gollum/Smeagle since we can trust Sam to control/watch over. </p> </li> <li> <p>Theory: Singular Learning Theory (this I will need some more quiet time to look into)</p> </li> <li> <p>Evals: Conversation with Lucas Sato</p> </li> <li> <p>Computer Policy/Security: Lots of discussion on controlling access to chips and protecting model weights from being exfiltrated (the act of a model or bad actor from \"stealing\" model weights). (Talk from Nick Marsh)</p> </li> <li> <p>Lots of Computer Science and Philosophy / Law people: I don't understand Bayesian Epistemology but hope to understand more in the future!</p> </li> </ol>"},{"location":"notes/reflections/NeurIPS_2025_Mech_Interp_Workshop/","title":"NeurIPS Mech Interp Workshop 2025","text":"<p>Date: 25.12.07</p> <p>Location: San Diego Convention Center</p> <p>Time: The whole day! 4 hours of driving from LA to San Diego but definitely worth it!</p>"},{"location":"notes/reflections/NeurIPS_2025_Mech_Interp_Workshop/#notes","title":"Notes","text":"<ol> <li> <p>Very nice to see the different perspectives in the mechanistic interpretability community specifically <code>Curiosity</code> and <code>Ambitious Mechanistic Interpretability (AMI)</code> and <code>Pragmatic Interpretability</code></p> </li> <li> <p>Some very cool people to learn from (and was really cool meeting them), Sarah from Transluce, Neel Nanda, David Bau, Leo Gao, J</p> </li> <li> <p>Takeaways</p> <ul> <li>LLMs are probabilistic/continuous models of cognition; approaches like SAE and Linear probes for interpretability seek to find symbolic/discrete representations</li> <li>When thinking about distributed/connectionist and localist models of the world, it seems that the world is inherently continuous/probabilistic and our models of cognition can create symbolic/discrete representations as abstractions</li> <li>Pragmaticism and Ambition/Curiosity are two sides of the same coin. Similar to the understanding above, perhaps we should channel our curiosity through measurable proxy goals so that we can progress on our ambitious overarching goals</li> <li>Probing a models inverse scope quantification could be an interesting way to probe how models represent empirical language phenomena (English vs. Mandarin representations) through the intersection of multilingualism and semantics</li> </ul> </li> </ol> Snippet of Cross-linguistics Inverse Scope Probe <p>Also, this past weekend I had the chance to attend the AI conference, NeurIPS, and started thinking about what it would mean to reproduce Scrontas et al. on Cross-linguistic scope ambiguity! So far, I've prompted a few frontier models (GPT-5, Claude, Gemini, and DeepSeek) and found that for the most part models allow for the inverse scope with a Mandarin prompt which should not be allowed. Some recent Mechanistic Interpretability research has found that \"shared circuitry increases with model scale\" so larger models share more latent representations (Brinkmann et al. 2025). When the winter holiday rolls around I'm curious to do a more rigorous probe of how multilingual models may represent (or not represent) inverse scope with perhaps both results being interesting! </p>"}]}